---
layout: distill
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST
bibliography: all.bib
disqus_comments: false
giscus_comments: false
date: 2024-04-29
featured: true
title: 'Early Experiments on Sparse Autoencoding (SAE)'
description: 'ì‹ ê²½ë§ì˜ í‘œí˜„ì— ìˆ¨ì–´ìˆëŠ” ìˆ˜ë§ì€ íŠ¹ì§•ë“¤ì„ ì°¾ì•„ë‚´ê¸° ìœ„í•´ì„œ ìµœê·¼ ì—°êµ¬ë˜ëŠ” SAE ê¸°ë²•ì„ ì¶”ì¢…í•˜ê¸° ìœ„í•´ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ë‹¤. '
---

ëª¨ë¸ì˜ í‘œí˜„ì„ í•´ì„í•œë‹¤ëŠ” ê²ƒì€ íŠ¹ì • ì•¡í‹°ë² ì´ì…˜ íŒ¨í„´ì´ ì§€ë‹ˆëŠ” ì˜ë¯¸ë¥¼ ë°ì´í„°ì™€ ì—°ê²° ì§“ëŠ” ê²ƒì´ë‹¤. ìµœê·¼ ì•Œë ¤ì§„ ë°”ì— ë”°ë¥´ë©´ ëª¨ë¸ì´ íŠ¹ì§•ì„ ì €ì¥í•˜ê¸° ìœ„í•´ì„œ ë³µìˆ˜ ê°œì˜ ë‰´ëŸ°ì´ íŠ¹ì • íŒ¨í„´ì„ ë§Œë“¤ì–´ì„œ ì €ì¥í•œë‹¤ëŠ” ê²ƒì´ ì•Œë ¤ì¡Œë‹¤. ì´ ì‚¬ì‹¤ì€ ê¸°ì¡´ì— binaryì ì¸ ë‰´ëŸ°ì˜ ì¼œì§€ê³  êº¼ì§€ëŠ” í˜„ìƒìœ¼ë¡œ íŠ¹ì§•ì˜ ìœ ë¬´ë¥¼ íŒë‹¨í–ˆë˜ ê²ƒì„ ë„˜ì–´ì„œ íŠ¹ì • ì•¡í‹°ë² ì´ì…˜ íŒ¨í„´ì´ ì˜ë¯¸ë¥¼ ì§€ë‹Œë‹¤ëŠ” ì‚¬ì‹¤ì„ ë‚˜íƒ€ë‚¸ë‹¤. ì¶•ì•½ëœ ì°¨ì›ì— ì €ì¥ëœ ë¬´ìˆ˜íˆ ë§ì€ íŠ¹ì§•ì„ ì°¾ê¸° ìœ„í•´ì„œ ì—°êµ¬ìë“¤ì´ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì€ dictionary learningì´ë‹¤. íŠ¹ì§•ì¸ íŒ¨í„´ì„ ì§‘ì–´ë„£ê³ , ë‹¤ì‹œ ë³µì›í•˜ëŠ” ê°„ë‹¨í•œ ë¬¸ì œì—ì„œ ë‚´ë¶€ì— ë¬´ìˆ˜íˆ ë§ì€ featureë“¤ì„ ì €ì¥í•˜ê³  ì„ íƒí•˜ëŠ” ë°©ì‹ì€, ê·¸ë“¤ì˜ linear sumì´ ì‹ ê²½ë§ì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚¸ë‹¤ëŠ” ê°€ì •ì„ ë³´ì¸ë‹¤. 

ë‚˜ëŠ” ì´ ì—°êµ¬ë¥¼ ì¶”ì¢…í•˜ê¸° ìœ„í•´ì„œ ì½”ë“œë¥¼ êµ¬í˜„í•˜ê³  ì‹¤í—˜í•˜ì˜€ë‹¤. Wikipedia 10ë§Œê°œ ë¬¸ì„œì— ëŒ€í•´ì„œ Llama2ì˜ activationì„ ìˆ˜ì§‘í•˜ì—¬ SAE í•™ìŠµì„ ì§„í–‰í•˜ì˜€ë‹¤. 
ì´ ë¶€ë¶„ì€ ê·¸ ê¸¸ì—ì„œ ê°€ì¥ ê°„ë‹¨í•œ êµ¬ì¡°ë¡œë¶€í„° ë¬´ì—‡ì´ ì˜ë˜ê³  ì•ˆë˜ëŠ”ì§€ íŒŒì•…í•˜ê¸° ìœ„í•œ ì—°êµ¬ì˜€ë‹¤. ì‹¤í—˜ ê²°ê³¼, ëª¨ë¸ì˜ ì¸µì´ ë†’ì•„ì§ˆìˆ˜ë¡ Reconstructionì´ ì œëŒ€ë¡œ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ê³ , GatedSAEëŠ” ë” ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ì´ëŠ” Neuron Resamplingê¸°ë²•ì„ ì ìš©í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ê·¸ëŸ° ê²ƒì´ë‹¤. 


* ğŸ§‘ğŸ»â€ğŸ’» Code Implementation [[Github](https://github.com/fxnnxc/llm/tree/v24.05.05_SAE)]
* ğŸ§‘ğŸ»â€ğŸ’» PseudoCode Implementation [[Gist](https://gist.github.com/fxnnxc/35a72b2af899a6f339bb9d2aa09ab563)]


## ì•„í‚¤í…ì²˜ 

###  SAEs
$$
f(x) = ReLU(W_{enc} (x- b_{dec}) + b_{enc}) \\ 
\hat{x}(f) = W_{dec}f + b_{dec}
$$

$$
L(x) =  || x - \hat{x}(f(x)) ||_2^2  + \lambda ||f(x)||_1
$$

### Gated SAEs

$$
\hat{f}(x) = 1[W_{gate}(x-b_{dec} +b_{gate}) >0] \odot ReLU(W_{mag} (x- b_{dec}) + b_{mag})
$$

where $1[\cdot >0]$ is the pointwise Heavyside step function and $\odot$ denotes elementwise multiplication. 
To reduce the number of weights, the authors set the weight
$$
(W_{mag})_{ij} =  (\exp(r_{mag}))_i \cdot (W_{gate})_{ij}
$$
where $r_{mag} \in \mathbb{R}^M$ is the rescaling parameter. 

$$
L_{incorrect}(x) = L(x) =  || x - \hat{x}(f(x)) ||_2^2  + \lambda ||f_{gate}(x)||_1
$$



## í‰ê°€ 

### 1. Reconstruction

í‘œí˜„ì„ Dictionary learningìœ¼ë¡œ ê²°í•©í•˜ì˜€ì„ ë•Œ ë³µì›ë ¥

$$
\Vert x - \hat{x}(f(x)) \Vert_2^2 
$$

### 2. L0 
í‘œí˜„ì„ Dictionary learningìœ¼ë¡œ ê²°í•©í•˜ì˜€ì„ ë•Œ ë³µì›ë ¥ì— í•„ìš”í–ˆë˜ ì•„ì´í…œ ê°œìˆ˜ 

L0 be the number of non zero features  

$$L0 = \mathbb{E}_{X\sim D} \Vert f(x)\Vert_0$$  

### 3. loss recovered 

í‘œí˜„ì„ Dictionary learningìœ¼ë¡œ ê²°í•©í•˜ì˜€ì„ ë•Œ ë³µì›ë ¥ (ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜)

$$
1 - \frac{CE(\hat{x} \cdot \hat{f}) - CE(ID)}{CE(\psi) - CE(ID)}
$$

where 
* $x \mapsto x$ :  the identity function, $\psi: x \mapsto 0$ the zero-ablation and $\hat{x} \cdot \hat{f}$ is autoencoder.
* When the ID is recovered with SAE, the score is 1. 

## ë°ì´í„° 

* LLama2 Activations 
* Layers: 2, middle, -2  (early, and later)
* Wikipedia: 100,000ê°œ. (from fever dataset)

---

## ì´ˆê¸° ì‹¤í—˜ ê²°ê³¼ 

1. lr_scheduler: `cosine hard restart`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, í•™ìŠµì— íš¨ê³¼ê°€ ì¢‹ì§€ ì•Šë‹¤. 
2. gatedSAEì˜ ê²½ìš°, SAEë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤. (ë…¼ë¬¸ì—ì„œëŠ” Neuron Resamplingì„ í•˜ì˜€ë‹¤ê³  í•œë‹¤. ì´ ë¶€ë¶„ì´ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë³´ì¸ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ì™œëƒí•˜ë©´, gateê°€ ì¼œì§€ëŠ” ê²½ìš°, gateì— Biasê°€ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. )
3. early, middle, laterì— ëŒ€í•´ì„œ ì•ì˜ ë‘ ê°œëŠ” í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì—ˆì§€ë§Œ, ë§ˆì§€ë§‰ì€ í•™ìŠµë˜ì§€ ì•Šì•˜ë‹¤. 
4. L1 coefficientëŠ” í•˜ëŠ” ë§Œí¼ Reconstructionì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. 

<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%218851&authkey=%21ABvIo6RPLoT1Oao&width=746&height=578" width="746" height="578" />

### ì™œ ë ˆì´ì–´ê°€ ì˜¬ë¼ê°ˆìˆ˜ë¡ Reconstructionì€ ë˜ì§€ ì•ŠëŠ”ê°€? 

íŠ¹ì§•ì´ë¼ëŠ” ê²ƒì€ ê²°ì •ì ì´ê³ , ê³ ì •ì ì¸ ì„±ì§ˆì„ ì§€ë…€ì•¼ í•œë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ê³  ì‹¤í—˜ì„ ìƒê°í•´ë³´ì. 

1. ë ˆê³ ë¥¼ ì—¬ëŸ¬ ê°œ ë³´ì—¬ì¤€ë‹¤. (input batch)
2. ë ˆê³ ë¥¼ êµ¬ì„±í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë“¤ì„ ê³ ë¥´ë¼ê³  í•œë‹¤. (items)
3. ì»´í¬ë„ŒíŠ¸ë“¤ì„ ê²°í•¨í•˜ì—¬ ê° ë ˆê³ ë“¤ì„ ëª¨ë‘ ë³µì›í•˜ë¼ê³  í•œë‹¤ (selection)
4. ì›ë˜ ë ˆê³ ë“¤ê³¼ ê°ê° ë¹„êµí•œë‹¤. (reconstruction)

ì „ì²´ ê³¼ì •ì—ì„œ 2, 3ë²ˆì€ ë”¥ëŸ¬ë‹ì˜ End-to-End í•™ìŠµì„ í†µí•´ì„œ ì ì ˆí•œ Item í‘œí˜„ê³¼ selectionì„ ì°¾ëŠ” ê³¼ì •ì´ë‹¤. 
ê·¸ ê³¼ì •ì—ì„œ Itemì˜ í‘œí˜„ì´ ì ì ˆí•˜ì§€ ì•Šê±°ë‚˜ selectionë¶€ë¶„ì´ ì ì ˆí•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. 

ë ˆì´ì–´ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ í•™ìŠµë˜ì§€ ì•Šì•˜ë˜ ê²ƒì€ ë‘ ê°€ì§€ ëª¨ë‘ ì˜í–¥ì„ ë¼ì¹˜ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ëœë‹¤. 
ì¦‰, ë ˆì´ì–´ê°€ ì˜¬ë¼ê°€ë©´ì„œ ë‹¤ìŒ ë¬¸ì œê°€ ìƒê¸´ë‹¤. 

<blockquote>
ë³µì¡í•œ ë ˆì´ì–´ì˜ í‘œí˜„ê³µê°„ì— ëŒ€í•´ì„œ ì ì ˆí•œ <strong>Primitive component</strong>ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ”ê°€? (No)
</blockquote>

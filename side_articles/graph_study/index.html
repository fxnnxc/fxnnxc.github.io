<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | Graph Neural Network</title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="Summary of learning graph neural network" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/side_articles/graph_study/">
    
    <!-- Dark Mode -->
    

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Graph Neural Network",
      "description": "Summary of learning graph neural network",
      "published": "August 30, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="https://fxnnxc.github.io/" style="margin-left:20px ;">
              <!--Bumjini-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">Bumjini    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->
              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_papers/"> Papers</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_articles/"> Articles</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_projects/"> Projects</a>
              </li>

              <!-- Other pages -->
              <li style="font-size: 17px" class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Others</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/side_papers/">üóÇÔ∏è side-paper</a>
                  <a class="dropdown-item" href="/side_articles/">ü•ï side-articles</a>
                  <a class="dropdown-item" href="/book/">üìö book (korean)</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">Graph Neural Network</h1>
        <p>Summary of learning graph neural network</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="graph-study">Graph Study</h2>

<p>I started studying graph neural network following lectures Stanford CS224W [<a href="https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn" target="_blank" rel="noopener noreferrer">playlist</a>]. This post is the summary and my thoughts on the materials covered in the lectures.</p>

<hr>

<h2 id="-lecture-11-youtube">ü™¥ Lecture 1.1 <a href="https://www.youtube.com/watch?v=JAB_plj2rbA" target="_blank" rel="noopener noreferrer">[Youtube]</a>
</h2>

<p>This section explains several graphs based on data types, necessity of graph representations, and covered materials in the lectures.  In a graph, entities (vertices) have relationships to each other. Based on the entity and relation types, there are several graph representations.</p>

<h3 id="examples-of-graphs-based-on-data-types">Examples of Graphs based on Data Types</h3>
<ul>
  <li><em>Event Graphs</em></li>
  <li><em>Computer Networks</em></li>
  <li><em>Disease Pathways</em></li>
  <li><em>Food Webs</em></li>
  <li><em>Particle Networks</em></li>
  <li><em>Underground Networks</em></li>
  <li>
<em>Social Network</em> : Society is a collection of 7+ billion  individuals</li>
  <li>Economic Networks</li>
  <li>Communication Network : Electronic devices, phone calls, financial transactions</li>
  <li>Brain Connections : our thoughts are hidden in the connections between billions of neurons</li>
  <li>Knowledge Graphs</li>
  <li>Code Graphs</li>
  <li>Molecules : atoms are vertices and connections (bonds) are edges</li>
  <li>3D Shapes</li>
  <li>Similarity networks</li>
  <li>Relational structures</li>
</ul>

<blockquote>
  <p>Network or Graph? <br> Sometimes the distinction between networks and graphs is blurred.</p>
</blockquote>

<h3 id="difference-between-graph-and-other-representations">Difference between Graph and other representations</h3>

<p>Complex domains have a rich relational structure, which can be represented as a graph. The features of graph are as follows:</p>

<ul>
  <li>Networks are complex : arbitrary size and complex topological structure</li>
  <li>No fixed node ordering or reference point</li>
  <li>Dynamic and multimodal features.</li>
</ul>

<h3 id="what-can-we-do-with-graph">What can we do with graph?</h3>

<p>Note that the goal of graph is mostly learning representation, that is, having a good representation of graphical data. As such, the input is <code class="language-plaintext highlighter-rouge">network</code> and output is several graph components such as <code class="language-plaintext highlighter-rouge">Node labels</code>, <code class="language-plaintext highlighter-rouge">New links</code>, <code class="language-plaintext highlighter-rouge">Generated graphs</code> and <code class="language-plaintext highlighter-rouge">subgraphs</code>. 
With the progress of deep learning, we can automatically extract informative features. A deep neural network map nodes to d-dimensional embeddings such that similar nodes in the network are embedded close together.</p>

<ul>
  <li>Traditional methods : Graphlets, Graph Kernels.</li>
  <li>Methods for node embeddings : DeepWalk, Node2Vec</li>
  <li>Graph Neural Networks :  GCN, GraphSAGE, GAT, Theory of GNNs</li>
  <li>Knowledge graphs and reasoning : TransE, BetaE</li>
  <li>Deep generative models for graphs</li>
  <li>Applications to Biomedicine, Science, Industry</li>
</ul>

<hr>

<h2 id="-lecture-12-youtube">ü™¥ Lecture 1.2 <a href="https://www.youtube.com/watch?v=aBHC6xzx9YI&amp;list=RDCMUCBa5G_ESCn8Yd4vw5U-gIcg&amp;index=2" target="_blank" rel="noopener noreferrer">[Youtube]</a>
</h2>

<p>Lecture 1.2 is about basic components (node and edge) and its applications.
The level of graph representation can be seen as</p>

<ul>
  <li>Node Level</li>
  <li>Community level (subgraph)</li>
  <li>Graph-level</li>
  <li>Edge-Level</li>
</ul>

<p>With such representations possible tasks are</p>

<ul>
  <li>
<strong>Node classification</strong> : predict a property of a node (Categorize online users / items)</li>
  <li>
<strong>Link prediction</strong> : predict whether there are missing links between two nodes</li>
  <li>
<strong>Graph classification</strong> : Categorize different graphs</li>
  <li>
<strong>Clustering</strong> : Detect if nodes from a community (social circle detection)</li>
  <li>
<strong>Graph generation</strong> : Drug discovery</li>
  <li>
<strong>Graph evolution</strong> : physical simulation</li>
</ul>

<h2 id="node-level-example--protein-3d-structure">Node Level Example : Protein 3D structure</h2>

<p>Protein is a sequence of Amino acids. Can we predict 3D structure based solely on its amino acid sequence?
The key idea of Alphafold <d-cite key="jumper2021highly"></d-cite> is spatial graph where</p>
<ul>
  <li>
<strong>Nodes</strong> : Amino acids in a protein sequence</li>
  <li>
<strong>Edges</strong> : Proximity between amino acids (residues)</li>
</ul>

<center>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Protein_folding_figure.png/450px-Protein_folding_figure.png" style="width:70%">
<figcaption>
      <p>Figure. Alphafold inference of 3D structure given a sequence of amino acid. <br> Image from Wikipedia <a href="https://en.wikipedia.org/wiki/AlphaFold" target="_blank" rel="noopener noreferrer">Alphafold</a>.</p>
    </figcaption>
</figure>
</center>

<h2 id="edge-level">Edge Level</h2>

<p>Unlike node level, edge level is a task of finding proper edges. For example, when users interact with items, the goal is 
to recommend items users might like (predict links). Task learn node embeddings $z_i$ such that</p>

\[d(z_{cake_1}, z_{cake_2} ) &lt; d(z_{cake_1}, z_{sweater} )\]

<h4 id="example-drug-side-effects">Example: Drug Side Effects</h4>

<p>Many patients take multiple drugs to treat complex or co-existing diseases: For example, 46% of people ages 70-79 take more than 5 drugs (in US) and many patients take more than 20 drugs to treat heart disease, depression, insomnia, etc.</p>

<p><strong>üë®‚Äç‚öïÔ∏èTask</strong>: Given a pair of drugs predict adverse side effects</p>

<ul>
  <li>Nodes : Drugs &amp; Proteins</li>
  <li>Edges : Interactions (side effects)</li>
  <li>Query : How likely will Simvastatin and Ciprofloxacin, when taken together break down muscle tissue?</li>
</ul>

<p>The edge (side effect) can even help discovering new side effects.</p>

<hr>

<h2 id="-lecture-13-youtube">ü™¥ Lecture 1.3 <a href="https://www.youtube.com/watch?v=P-m1Qv6-8cI&amp;list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&amp;index=3" target="_blank" rel="noopener noreferrer">[Youtube]</a>
</h2>

<p>Finally, lecture 1.3 deals with basic notations in graph representations such as nodes, edges, degree, and components. When we use graph representations, we must set proper features in data to make node and edges. The choice of the proper network representation of a given domain/problem determines our ability to use network successfully.</p>

<ul>
  <li>Objects : nodes, vertices $N$</li>
  <li>Interactions : links, edges $E$</li>
  <li>System : network, graph $G(N, E)$</li>
</ul>

<h3 id="undirected-vs-directed">Undirected vs Directed</h3>

<h4 id="undirected">Undirected</h4>
<p>A graph with no directional edges. For example, collaborations, friendship on facebook. 
<br> Node degree $k_i$ and average degree : $\bar{k} = &lt; k &gt; = \frac{1}{N} \sum_{i=1}^N k_i = \frac{2E}{N}$</p>

<h4 id="directed">Directed</h4>
<p>A graph with directional edges. For example, phone calls, following in tweets. 
<br> $\bar{k}^{in} = \bar{k}^{out}= \frac{E}{N}$ : the number of in-degree and out-degree is same.</p>

<h4 id="bipartite-graph">Bipartite Graph</h4>
<p>A graph with two disjoint sets $U$ and $V$</p>

<ul>
  <li>Authors-to-Papers (they authored)</li>
  <li>Actors-to-Movies (they appeared in)</li>
  <li>Users-to-Movies (they rated)</li>
</ul>

<h4 id="folded-networks-">Folded Networks :</h4>

<p>project two sets in the bipartite graph respectively. For example, authors collaboration networks</p>

<center>
<figure>
<img src="https://drive.google.com/uc?export=view&amp;id=12KRTKN9v2aYFbpQYuOfsM_o7rn0QMl8i" style="width:70%">
</figure>
</center>

<h4 id="adjacency-matrix">Adjacency Matrix</h4>

<p>$A_{ij}=1$ if there is a link from node $i$ to node $j$ and $A_{ij}=0$ otherwise.</p>

<h4 id="represent-graph-as-a-list-of-edges">Represent graph as a list of edges</h4>

<p>Most real-world networks are sparse  $E ¬´¬†E_{max}$</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>G = {(1,2), (2,3), (3,4), (3,2)}
</code></pre></div></div>

<h4 id="adjacency-list">Adjacency list</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>G is a form of 
1: [] 
2: [3,4,5]
3: [3,4,6]
</code></pre></div></div>

<h4 id="possible-options">Possible Options</h4>

<ul>
  <li>Weight (frequency of communicating )</li>
  <li>Ranking (best friend, second friend)</li>
  <li>Type  (friend, relative, co-worker)</li>
  <li>Sign (Friend vs Foe, Trust vs Distrust)</li>
</ul>

<h4 id="strongly-connected-directed">Strongly Connected Directed</h4>

<p>Strongly connected directed graph  has a path from each node to every other node and vice versa (A-B path and B-A path)
Weakly connected directed graph  : is connected if we disregard the edge directions</p>

<h4 id="strongly-connected-components-scc">Strongly Connected Components (SCC)</h4>

<p>Strongly connected components (SCCs) can be identified, but not every node is part of a nontrivial strongly connected component.</p>

<ul>
  <li>In-component: nodes that can reach the SCC</li>
  <li>Out-component: nodes that can be reached from the SCC. <br> (starting from SCC node to the component)</li>
</ul>

<hr>

<h2 id="lecture-2">Lecture 2</h2>

<ul>
  <li>Node degree : the number of edges the node has.</li>
  <li>Node centrality : take the node importance in a graph into account
    <ul>
      <li>Eigenvector centrality  $c_v = \frac{1}{\lambda} \sum_{u \in N(v)} c_u$</li>
      <li>Betweenness centrality : if a node lies on many shortest paths between other nodes (used for a path)</li>
      <li>Closeness : shortest path is smaller than other nodes. (close to other nodes)</li>
    </ul>
  </li>
  <li>Clustering coefficient : how connected v‚Äôs neighboring nodes are (for all combination of neighboring nodes, how many of them are connected. )</li>
  <li>Graphlets : isomorphic components in graph.</li>
</ul>

<hr>

<h3 id="eigenvector-centrality">Eigenvector Centrality</h3>

<p>Let $v$ be a node of a graph $\mathcal{G}$ with $v = 1, 2, \cdots, N$. <code class="language-plaintext highlighter-rouge">The eigenvector centrality</code> $c_v$ of node $v$ is defined by  $c_v = \frac{1}{\lambda} \sum_{w\in N(v)} c_w$. As centrality score $c_v$ is defined by other centrality scores $c_w$, which is again determined by other centrality scores, this equation makes <strong>simultaneous equations for centrality score $c_v$ with all $v\in V$</strong> where $V$ is the set of nodes. 
In other words, in the following form with some function $f$</p>

\[\begin{bmatrix}
c_1 \\
c_2 \\ 
\vdots \\ 
c_N
\end{bmatrix} = 
f \Big(\begin{bmatrix}
c_1 \\
c_2 \\ 
\vdots \\ 
c_N
\end{bmatrix} \Big)\]

<p>As the neighbors $N(v)$ determines adjacency vector $A_v$ of node $v$, summation part $\sum_{w\in N(v)}$ could be replaced by an adjacency vector such as $[1,0,1,0,0,\cdots]$. As such, we obtain the following <strong>simultaneous equation of centrality scores</strong> with the adjacency matrix $A$ of graph $\mathcal{G}$ :</p>

\[\begin{align}

\lambda \cdot \begin{bmatrix}
c_1 \\
c_2 \\ 
\vdots \\ 
c_N
\end{bmatrix} =
 \begin{bmatrix}
 &amp; A_1 &amp; \\
 &amp; A_2 &amp; \\
&amp; \vdots &amp; \\ 
 &amp; A_N &amp;
\end{bmatrix} &amp; 
 \begin{bmatrix}
c_1 \\
c_2 \\ 
\vdots \\ 
c_N
\end{bmatrix} \\ 
 = \begin{bmatrix} &amp; &amp;  \\&amp;  A  &amp;  \\  &amp; &amp; \end{bmatrix}
 &amp; \begin{bmatrix}
c_1 \\
c_2 \\ 
\vdots \\ 
c_N
\end{bmatrix} 
\end{align}\]

<p>Solving this equation is equal to finding an eigenvector. 
Note that the equation requires only <strong>finding a single eigenvector</strong> and <strong>each element of the vector is the centrality score of each node</strong>.</p>

<blockquote>
  <p>The eigenvector with the largest eigenvalue is the desired centrality measure. See [<a href="https://en.wikipedia.org/wiki/Eigenvector_centrality" target="_blank" rel="noopener noreferrer">wiki</a>]</p>
</blockquote>

<hr>

<p>Graphlet Degree Vector (GDV) : a count vector of graphlets rooted at a given node. For example, [2,1,0,0] where each index is the isomorphic graphlet.</p>

<p>Importance-based Features vs Structure-based Features</p>
<ul>
  <li>I  : node degree, centrality measures</li>
  <li>S  : node degree, clustering, graphlets</li>
</ul>

<h2 id="node-representation">Node Representation</h2>

<p>Goal : Efficient task-independent feature learning</p>

<p>Task: map nodes into an embedding space</p>
<ul>
  <li>
    <p>Similarity of embeddings between nodes indicates their similarity in the network.</p>
  </li>
  <li>
    <p>DeepWalk : Online learning of social representations. (KDD2014)</p>
  </li>
</ul>

<p>Goal : similarity $(u, v) \approx z_v^\top z_u$</p>
<ol>
  <li>Encoder : maps from notes to embeddings  $ENC(v) = z_v$ (just embedding-lookup) (very large as the parameter increases as the number of nodes.)</li>
  <li>Decoder : maps from embeddings to the similarity score $\operatorname{similarity(u,v)} \approx z_v^\top z_u $</li>
</ol>

<h4 id="random-walk-embedding">Random Walk Embedding</h4>

<ul>
  <li>Negative Sampling :</li>
</ul>

\[\log (\frac{\exp (z_u^\top z_v)}{\sum_{n\in V} \exp (z_u^\top z_n)}) \\ 
\log\Big( \sigma(z_u^\top z_v) \Big) - \sum_{i=1}^k \log \Big( \sigma(z_u^\top z_{n_i}) \Big)\]


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--<div id="disqus_thread" style="max-width: 1000px; margin: 0 auto;">
    <script type="text/javascript">
        var disqus_shortname  = 'al-folio';
        var disqus_identifier = '/side_articles/graph_study';
        var disqus_title      = "Graph Neural Network";
        (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
    </div>
 -->
      <hr>
<div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;">
    <script>
      let giscusTheme = localStorage.getItem("theme");
      let giscusAttributes = {
          "src": "https://giscus.app/client.js",
          "data-repo": "fxnnxc/fxnnxc",
          "data-repo-id": "MDEwOlJlcG9zaXRvcnkzMjQ2NjUxMTU=",
          "data-category": "Q&A",
          "data-category-id": "DIC_kwDOE1n_G84CYOk_",
          "data-mapping": "title",
          "data-strict": "0",
          "data-reactions-enabled": "1",
          "data-emit-metadata": "0",
          "data-input-position": "top",
          "data-theme": giscusTheme,
          "data-lang": "en",
          "crossorigin": "anonymous",
          "async": "",
      };
  
  
      let giscusScript = document.createElement("script");
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById("giscus_thread").appendChild(giscusScript);
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by giscus.</a>
</noscript>
  </div>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  <center>
    <a  href="">
    <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </a>
  </center>
  <hr> 

  </html>

<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | Investigating Instability of Messages in <br> Multi-agent Reinforcement Learning</title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="Stability analysis of hidden representation messages in multi-agent." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/side_papers/instability_of_messages_in_marl/">
    
    <!-- Dark Mode -->
    

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Investigating Instability of Messages in <br> Multi-agent Reinforcement Learning",
      "description": "Stability analysis of hidden representation messages in multi-agent.",
      "published": "August 12, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="https://fxnnxc.github.io/" style="margin-left:20px ;">
              <!--Bumjini-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">Bumjini    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->
              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_papers/"> Papers</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_articles/"> Articles</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_projects/"> Projects</a>
              </li>

              <!-- Other pages -->
              <li style="font-size: 17px" class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Others</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/side_papers/">üóÇÔ∏è side-paper</a>
                  <a class="dropdown-item" href="/side_articles/">ü•ï side-articles</a>
                  <a class="dropdown-item" href="/book/">üìö book (korean)</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">Investigating Instability of Messages in <br> Multi-agent Reinforcement Learning</h1>
        <p>Stability analysis of hidden representation messages in multi-agent.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h1 id="introduction">Introduction</h1>

<p>Environment is a complex space where several agents and objects make interactions. 
In the environment, rational agents act to maximize utilities and the action is learned by reinforcement learning algorithm (RL) with a deep neural network. 
As the most of environments are non-stationary, a single agent can not achieve the maximum utility only with its observation and inferences with a network. 
However, if multiple agents can communicate with each other, a single agent can get richer information about the states of the environment by simply obtaining messages from other agents. 
However, the inferred information from other agents are made by a neural network which is sometimes vulnerable and includes the personal perspective of the agent processed the information. 
For example, even though there is a single observation, two agents can encode very different messages as parameters and modules could be different.</p>

<p>Therefore, it is important to consider the subjectivity of messages in multi-agent reinforcement learning (MARL). 
Based on the assumption that the encoded information is a rather subjective information of the agent encode it, 
we tackle the problem of handling objective and subjective information in MARL. 
One limitation is that the processed information by a neural network is hardly interpreted. As the starting work of this subjectivity work, 
we tackle the most minor problem whether the subjective information is better than the objective information. 
In detail, we compare the usefulness of messages from an agent to another agent in two kinds: raw observation and the output of a neural network.</p>

<h1 id="related-work">Related Work</h1>

<p>Before proceeding, we review the previous methods in MARL.</p>

<blockquote>
  <p><strong style="font-style:normal">Learning Shared Q-values </strong> <br>
 <strong>QMIX</strong><d-cite key="rashid2018qmix"></d-cite> learns a mixing network of Q-values which outputs the mixed Q-value which is monotonically  increasing for agent Q-values. <strong>MADDPG</strong><d-cite key="lowe2017multi"></d-cite> utilizes the Q-functions conditional on broad casted information from agents and execute  agents in decentralized manner with the learned policy conditioned only on the observation of each agent.<br>
<strong>MAPPO</strong> (Multi-agent PPO)<d-cite key="yu2022surprising"></d-cite> utilizes the PPO with centralized value function inputs, while the value function of <strong>IPPO</strong> (Independent PPO)<d-cite key="de2020independent"></d-cite> takes an independent input.</p>
</blockquote>

<blockquote>
  <p><strong style="font-style:normal">Communication Skills </strong> <br>
<strong>TarMac</strong><d-cite key="das2019tarmac"></d-cite> utilizes the attention mechanism between agents to spread the values between communicated agents. The recurrent hidden states outputs two components query and  [key, value] vectors.  <strong>I2C</strong><d-cite key="ding2020learning"></d-cite> uses the prior network to determine whom to request a message. The difference with TarMac is the separation of communication steps. We believe I2C is discrete as due to the determination of agents to communicate. Note that TarMAC is based on Q-K communication.</p>
</blockquote>

<blockquote>
  <p><strong style="font-style:normal">Modeling What to Share </strong> <br>
<strong>LToS</strong><d-cite key="yi2022learning"></d-cite> is a hierarchical modeling of agents (bi-level optimization) where the high-level policy distributes the reward signals to neighbors and the low-level policy control agent each. The shared information is the reward of each agent and the information can benefit the cooperative MARL.</p>
</blockquote>

<p>Note that our problem is in the field of <strong>Communication Skills</strong> and <strong>Modeling What to Share</strong>, and is orthogonal to the previous methods as we design the package style rather than communication styles.</p>

<h1 id="proposed-method">Proposed Method</h1>

<p>Several MARL methods consider <em>how</em> to communicate between agents and make message with a deep neural network (DNN). 
As the output of the DNN automatically formed with the optimization algorithms, it is natural to think that the output of the agent is a compact information necessary to communicate between agents well. However, as the deep neural network is hardly interpreted, the passed message could be ambiguous and sometimes include errors. On the other hand, the observation of the agent is most unprocessed information which does not include the knowledge of the agent. Within the progress of the interpretation of DNN, we can find that the neurons in DNN are firing when they capture features in an observation.</p>

<p>We believe that the simplicity of the observation is necessary for the message, but the message may include some errors induced from the agent.  Therefore, the receiver of the message may distinguish two information to decide whether to accept the processed information or decline it.</p>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/subjectivity.png" style="width:100%">
<figcaption>
Comparison between the previous message passing and the subjectivity-based message passing. 
The previous method generate messages with a deep neural network and passed the information to the next agent. On the other hand, the subjectivity-based message pass a message which is gathered representations leveled by subjectivity. 
</figcaption>
</figure>

<h1 id="why-subjectivity">Why Subjectivity</h1>

<p>The general belief  of a DNN is that the hidden representation is a compact representation of the input. Therefore, it may not be necessary to gather information based on the subjectivity. 
However, the recent progress in the interpretability field have found that the internal neurons are activated by specific patterns and they form circuits for complex features <d-cite key="olah2020zoom"></d-cite><d-cite key="cammarata2021curve"></d-cite>. 
Therefore, it is natural to think that  two models can capture the very different concepts if their circuits are differently formed. In addition, the last output of a model is a complex feature of the input and could not encode enough information of the input. Therefore, the hidden representation have neither full input information nor common information between other models.</p>

<h1 id="message-passing-with-deep-neural-network">Message Passing with Deep Neural Network</h1>

<p>In this work, we propose gated message passing in the communication of multi-agent. Although the agents are trained with the RL framework to determine the action, the passage passing could be simply modeled with representation passing optimized by the behavior of the receiver agent. That is, the pipeline has an observation of the sender agent as input and the action of the receiver agent as output. 
Consider agent (s) as a sender and agent (r) as a receiver.</p>

<p>Let $o_t^{(s)} \in \mathbf{R}^{obs}$ be the observation of sender agent at time step $t$ and $h_t^{(s)} \in \mathbf{R}^d$ be the hidden message made by sender agent. The sender agent will pass both information $(o_t^{(s)},h_t^{(s)})$ to the receiver agent who will choose which information to take with gating scalar $\sigma^{(r)}$ to produce the processed message $g_t^{(r,s)}$.</p>

\[g_t^{(r,s)} = \sigma_t^{(r)} h_t^{(s)} + (1 - \sigma_t^{(r)})  \hat{o}_t^{(s)}\]

<p>where $\hat{o}$ is a linear transformation of observation $o$ to match the dimension with hidden representation.</p>

<h2 id="noised-message-testing">Noised Message Testing</h2>

<p>To test the effectiveness of the gating mechanism in message passing. We conduct simple observation passing settings. We train a single agent in RL with directly separate modules: Agent1 and Agent2. The Agent 2 processes the raw observation at the current time step with MLP, while Agent 2 processes the observation with RNN with hidden representations. In addition, we added noises to test the robustness of messages. 
The Figure below shows three types of message passings: (a) Is the case when the agent has only MLP to process the current observation, (b) is the case when RNN is applied to process the long horizontal information, and (c) is the gated neural network. Note that we add noise sampled from normal distribution in two parts: observation and hidden representation to test robustness.</p>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/cartpole_messages.png" style="width:70%">
<figcaption>
Three types of message passings used in this experiment. 
</figcaption> 
</figure>

<p>The Figure below shows the return averaged over 2 seeds. We observe that the gated agent has competent performance with the raw observation case, while hidden representation fails as the noise increases. These results indicate that the noise significantly hurt the performance.</p>
<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/cartpole_return.png" style="width:100%">
<figcaption>
Figure. The training return in CartPole-v0 environment over 100K samples averaged by 2 seeds.
</figcaption> 
</figure>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/cartpole_vf.png" style="width:100%">
<figcaption>
Figure.  The error of the value function in CartPole-v0 environment averaged over 2 seeds. 
</figcaption> 
</figure>

<p>To further provide analysis, we track the interpolation value while training. The result shows that the interpolation value increases from 1 to 1.2 which means the neural network learned to add hidden representations over training. Note that 1 is the initialized value which is the circumstance that the agent takes only the observation.</p>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/alpha.png" style="width:70%">
<figcaption>
Figure.  the interpolation value over training averaged over 2 seeds. 
</figcaption> 
</figure>

<h1 id="message-passing-in-multi-agent">Message Passing in Multi-Agent</h1>

<p>To further verify the effectiveness of gated message passing, we compare three modelings in multi-agent environment.We use MATE<d-cite key="pan2022mate"></d-cite>, which is a cooperative MARL environment where cameras and targets are intra-teams communicate respectively. The goal of the camera is to cover as many times the targets in its vision.The Figure below shows an example of a MATE environment.</p>

<figure style="text-align:center">
<img align="" src="https://user-images.githubusercontent.com/16078332/130274196-9d18563d-6d42-493d-8dac-326b1924d2e3.gif" style="width:30%">
<figcaption>
¬© Image From   <a href="https://github.com/UnrealTracking/mate" target="_blank" rel="noopener noreferrer">MATE github</a>
</figcaption>
</figure>

<p>In the environment, multi-agent communicate with each other with TarMAC model which computes attention scores to pass a hidden message generated from RNN. We designed a gated mechanism in the receiver agent which determines the ratio between a hidden representation or a raw observation (see the Figure below). We test two settings, 4vs2 and 2vs2 where the first number is the number of cameras and the second number is the number of targets.</p>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/simple_communication.png" style="width:100%">
<figcaption>
The two levels communication packages. The raw observation and the processed information of the agent are passed to the second agent. The second agent process the information with gating mechanism to determine the necessary information. 
</figcaption> 
</figure>

<p>The Figure below shows the training return over 4M time steps. 
The results showed that the gated message passing is effective when there are many agents (4vs2), while remaining similar performance in the small number of communications (2vs2). In addition, the 95% confidence region is very huge for hidden representation which indicates that the messages originated from a deep neural network could be unstable.</p>

<figure style="text-align:center">
<img align="" src="/assets/side_papers/subjectivitiy_information/mate.png" style="width:100%">
<figcaption>
Figure. The training return in MATE environment over 4M samples averaged by 2 seeds. 
</figcaption> 
</figure>

<h1 id="conclusion">Conclusion</h1>

<p>This work propose a gated message passing in multi-agent communication to mitigate the effect from unstable messages in deep neural network. Our work show that the message passing starting from raw observation and slightly adding hidden representation messages is an effective way of communication.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--
    </div>
 -->
      <hr>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  <center>
    <a  href="">
    <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </a>
  </center>
  <hr> 

  </html>

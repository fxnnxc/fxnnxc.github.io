---
layout: distill
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST
bibliography: all.bib
date: 2024-05-21
giscus_comments: true
title: 'Explanation on Safety Phase Transition in Large Language Models'
description: 'ì•ˆì „ì¥ì¹˜ë¡œ í•™ìŠµëœ ëª¨ë¸ì˜ phase transitionì— ëŒ€í•œ ì²´ê³„ì  ì—°êµ¬. ' 
---


## Motiv 

AI ëª¨ë¸ì€ ì¸ë¥˜ì— í•´ê°€ ë˜ëŠ” ë¬¸ì¥ì— ëŒ€í•´ì„œ ë§í•˜ì§€ ì•Šë„ë¡ ì¶”ê°€ì ì¸ í•™ìŠµì´ ëœë‹¤. 
ì•ˆì „í•œ ì‚¬ìš©ì„ ìœ„í•´ ëª¨ë¸ì€ ë‚˜ìœë§ì„ í•˜ëŠ” ëŒ€ì‹ , ê·¸ëŸ¬í•œ ë§ì„ í•˜ë©´ ì•ˆë˜ëŠ” ì´ìœ ë¥¼ ë§Œë“¤ì–´ ë‚¸ë‹¤. Safetyì™€ ê´€ë ¨ëœ ë§ì„ í•˜ë„ë¡ ìƒì„± ëª¨ë“œê°€ ë°”ë€ŒëŠ” safety phaseì— ëŒ€í•œ ì´í•´ëŠ” ë”ìš± ì•ˆì „í•œ ëª¨ë¸ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œ í•„ìˆ˜ì ì´ë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” instruction-tuned ëœ GPT ëª¨ë¸ì— ëŒ€í•œ ë‘ ê°€ì§€ ì‹¤í—˜ì ì¸ ê²°ê³¼ë¥¼ ì œì‹œí•œë‹¤. **ğŸ“Œ 1) ëª¨ë¸ì€ ì–´ë– í•œ ìƒí™©ì—ì„œ phaseê°€ ë°œìƒí•˜ëŠ”ê°€.** ì´ ì—°êµ¬ëŠ” safetyì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ë¬¸ì¥ì— ëŒ€í•´ì„œ ê° ë¬¸ì¥ì˜ í‘œí˜„ë“¤ì„ ë¹„êµí•˜ê³  í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ì „ë°˜ì ì¸ ëª¨ë¸ì˜ ì…ì¶œë ¥ì„ í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•œë‹¤.  **ğŸ“Œ 2) safetyëŠ” ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ triggerê°€ ë˜ëŠ”ê°€?** ëª¨ë¸ ë‚´ë¶€ì—ì„œëŠ” safetyì™€ ê´€ë ¨ëœ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•˜ëŠ” íŠ¹ì •í•œ í‘œí˜„ í˜¹ì€ ë‰´ëŸ°ì´ ì¡´ì¬í•œë‹¤. ì´ë¥¼ íƒêµ¬í•˜ì—¬ í•´ë‹¹ ë‰´ëŸ°ì˜ ì¡°ì‘ìœ¼ë¡œ safetyì™€ ê´€ë ¨ëœ ë¬¸ì¥ë“¤ì´ ì–´ë– í•œ ë³€í™”ë¥¼ ë³´ì´ëŠ”ì§€ íƒêµ¬í•œë‹¤. ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì€ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ë©° ê¸°ì¡´ ì •ë³´ë¥¼ ì§€ìš°ê³  ìƒˆë¡­ê²Œ ë®ì–´ì“´ë‹¤. ë˜í•œ ë¶€ì •ì ì¸ ì •ë³´ë“¤ì€ ìƒì„±ì„ ë§‰ë„ë¡ ì¶”ê°€ì ì¸ í•™ìŠµì´ ëœë‹¤. ë³¸ ì—°êµ¬ì—ì„œ íƒêµ¬í•˜ëŠ” safety phase transitionì€ ì•ˆì „ë¬¸êµ¬ì™€ ê´€ë ¨ëœ LLMì˜ ìƒì„±ê³¼ì •ì„ ë¶„ì„í•¨ìœ¼ë¡œì¨ ì‹¤í—˜ì  ê´€ì°°ì„ ë°”íƒ•ìœ¼ë¡œí•œ ë”ìš± ì•ˆì „í•œ ëª¨ë¸ êµ¬ì¡°ì— ëŒ€í•œ ì˜ê°ì„ ì œì‹œí•œë‹¤. 

## Collection of Papers 

* **Safety finetuning + deceiving** 
    * Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training
    * Simple probes can catch sleeper agents

* **Safety finetuning**
    * Training a helpful and harmless assistant with reinforcement learning from human feedback
    * Training language models to follow instructions with human feedback

* **Jail-break** 
    * Defending chatgpt against jailbreak attack via self-reminders
    * Many-shot Jailbreaking

* **Safety** 
    * Towards understanding sycophancy in language models

* **Interpretability (feature)**
    * Towards Monosemanticity: Decomposing Language Models With Dictionary Learning
    * Mapping the Mind of a Large Language Model


---



## Abstract 




## Introduction 



## Related Work



## Method


## Experiments 


## Results 


## Conclusion




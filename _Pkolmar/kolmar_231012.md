---
layout: share-distill
title: '[ì—°êµ¬ 3] Decision Tree & SVR'
date: 2023-10-08
giscus_comments : true
description: "First Receipt ë°ì´í„° ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ì ë„ ì˜ˆì¸¡"
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST
img: https://drive.google.com/uc?export=view&id=16-ZXy2tI6s72_agj7pzy4PTM7IrcB4hd
---


## 1. Report Info   

ë³¸ ê¸€ì—ì„œëŠ” `first_receipt` ì— ëŒ€í•´ì„œ Regression ëª¨ë¸ ë‘ ê°€ì§€ë¥¼ í•™ìŠµí•˜ì—¬, ì„±ëŠ¥ ë¹„êµë¥¼ ì§„í–‰í•œë‹¤. 
ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë¡œ í•™ìŠµí•´ë³¸ ê²°ê³¼ ë‹¨ìˆœ Decision Tree ê¸°ë°˜ ëª¨ë¸ì€ ì œëŒ€ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ì—†ìŒì„ í™•ì¸í•˜ì˜€ë‹¤. ì´ëŠ” Regression ì˜ˆì¸¡ì´ ìƒ˜í”Œì— ëŒ€í•œ í‰ê· ê°’ì„ ì‚¬ìš©í•˜ëŠ”ë°, ë…¸ë“œ ìˆ˜ê°€ ì ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ì˜ ë²”ìœ„ê°€ ì¤‘ì•™ì— ì˜¬ë ¤ìˆëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì´ì™€ëŠ” ë°˜ëŒ€ë¡œ ì…ë ¥ê°’ì— íšŒê¸°ì‹ì„ ë§Œë“¤ì–´ì„œ ì˜ˆì¸¡í•˜ëŠ” Support Vector Regression ëª¨ë¸ì€ ì„±ëŠ¥ì´ ë³´ì¥ë˜ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. ì½”ë“œ ê°œìˆ˜ì— ëŒ€í•´ì„œëŠ” ì½”ë“œê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ SVR ì€ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ëª¨ë‘ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆì§€ë§Œ, DT ëª¨ë¸ì€ ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šì•˜ê³ , íŠ¸ë¦¬ì˜ ê¹Šì´ë„ ë”ìš± ì¦ê°€í•˜ì§€ ì•Šì•˜ë‹¤. ë”°ë¼ì„œ, Regression ê¸°ë°˜ Decision TreeëŠ” ë¶€ì í•©í•œ ê²ƒì„ í™•ì¸í•˜ì˜€ê³ , ë”ìš± ë³µì¡í•œ Tree í˜•íƒœë¥¼ ê³ ë ¤í•  ê³„íšì´ë‹¤. 

í•œ ê°€ì§€ ì•„ì‰¬ìš´ ì ì€ Tree ê¸°ë°˜ ëª¨ë¸ì˜ í•´ì„ì˜ ìœ ìš©ì„±ì„ ì ‘ëª©í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•´ì„œ Classification ê¸°ë°˜ ëª¨ë¸ì— ëŒ€í•´ì„œ Tree ë¥¼ ì ìš©í•´ì•¼ í•˜ëŠ”ë°, ë ˆì´ë¸”ì„ 5000ë‹¨ìœ„ë¡œ ìƒì„±í•  ê²½ìš° 20ê°œ ì •ë„ì˜ ë ˆì´ë¸”ì´ ìƒê¸°ë¯€ë¡œ ë‹¨ìˆœ Decision Tree Classificationìœ¼ë¡œë„ ì„±ëŠ¥ì„ ë‚´ê¸° ì–´ë ¤ìš¸ ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤. ë³µì¡í•œ Treeì¸ Random Forest ë‚˜ XGBoost ì˜ í˜•íƒœë¥¼ ê³ ë ¤í•  ê³„íšì´ë‹¤. 


<div class="spanbox" markdown="1" style="width:40rem;background-color:#FFFDFD;">
1. ğŸ‘¨ğŸ»â€ğŸ’» **Code Release**:  Tag [v23.10.12.2](https://github.com/fxnnxc/kolmar/tree/v23.10.12.2)
2. ğŸ“‚ **Raw Data** :  (1, `raw_data:first_receipt`)
3. ğŸ—‚ï¸ **Datasets** :  (2, `ds:first_receipt_ml`)
4. ğŸ‘¾ **Models** :  (0, '`decision_tree_regressor`') / (1, `svr`)
5. ğŸ¦„ **Trainers** : (1, `sklearn_regressor`)
6. ğŸ“Œ **Related Notebooks** 
  * [svr_rmse.ipynb](https://github.com/fxnnxc/kolmar/blob/v23.10.12.1/labs/first_receipt_rmse/plot_rmse_svr.ipynb)
  * [dt_rmse.ipynb](https://github.com/fxnnxc/kolmar/blob/v23.10.12.1/labs/first_receipt_rmse/plot_rmse_tree.ipynb)
</div>



## 2. í•™ìŠµ ê²°ê³¼    
* í•™ìŠµ ëª¨ë¸ì€ ë‘ ê°€ì§€ Support Vector Regressor (SVR) ê³¼ Decision Tree Regressor (DT) 
* ì˜ˆì¸¡ ê°’ì€ 1/10000 ê°’ìœ¼ë¡œ ë‚®ì¶°ì„œ ì˜ˆì¸¡í•œë‹¤. 

## 2.1. Training RMSE (Root Mean Squared Error)

<div class="spanbox" markdown="1" style="width:100%">

* MSE : mean squared error 
* RMSE : root mean squared error 

$$ 
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

$$ 
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}
$$

ì•„ë˜ ê·¸ë¦¼ì€ ì…ë ¥ì— ì‚¬ìš©ëœ ì½”ë“œ ê°œìˆ˜ì— ë”°ë¼ì„œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. (ì¢Œ: SVR, ìš°:DT)

<img src="https://drive.google.com/uc?export=view&id=10-vwD_CzikpZFPvHji2Qs-EP-m8jb5TY" style='width:49%'>
<img src="https://drive.google.com/uc?export=view&id=1vbVyGzec2w298efKHKNzHVmOace7Wtdl" style='width:49%'>
</div>

--- 

## 2.2. Parameter Search

<div class="spanbox" markdown="1" style="width:100%">


ì—¬ëŸ¬ íŒŒë¼ë¯¸í„° ì¤‘ì—ì„œ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ”ë‹¤. 

### 2.2.1 Decision Tree 

<d-code language='python'>
param_grid = {
                    "splitter":["best","random"],
                    'max_depth': [1,2,3,5,7,9],
                    'min_samples_split': [2, 3, 4, 5, 10],
                    "min_weight_fraction_leaf":[0.1, 0.3, 0.5],
                    "max_features":["log2", "sqrt"],
                    "max_leaf_nodes":[None,10, 20, 30, 50, 100]
                    }
</d-code>

* Decision Tree : 'max_depth'

<img src="https://drive.google.com/uc?export=view&id=1rbjPF06wY8xkaIQfF2l-qW2XByNETeLp" style='width:100%'>


#### ì˜ˆì‹œ) ì½”ë“œ 100 ê°œ ëª¨ë¸ 

í•™ìŠµ ì™„ë£Œ í›„, í•™ìŠµëœ ëª¨ë¸ì˜ ì •ë³´ë¥¼ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 

<d-code language='python'>

best_params:
  max_depth: 7
  max_features: sqrt
  max_leaf_nodes: null
  min_samples_split: 2
  min_weight_fraction_leaf: 0.1
  splitter: random
train_results:
  rmse: 1.2203531353731971
test_results:
  rmse: 1.2753255313844698

|--- GYH026 <= 4.52
|   |--- HJK244 <= 0.55
|   |   |--- FGH202 <= 2.84
|   |   |   |--- CVB114 <= 0.57
|   |   |   |   |--- XCV072 <= 3.86
|   |   |   |   |   |--- value: [5.10]
|   |   |   |   |--- XCV072 >  3.86
|   |   |   |   |   |--- value: [5.46]
|   |   |   |--- CVB114 >  0.57
|   |   |   |   |--- value: [4.88]
|   |   |--- FGH202 >  2.84
|   |   |   |--- value: [4.76]
|   |--- HJK244 >  0.55
|   |   |--- value: [4.09]
|--- GYH026 >  4.52
|   |--- value: [5.87]

</d-code>

---

<img src="https://drive.google.com/uc?export=view&id=1mtE_2yeXeac1vUJF_b75SSPEGDPoX0Tv" style='width:100%'>


**ë‹¨ìˆœ Tree ëª¨ë¸ì€ í•™ìŠµì´ ê±°ì˜ ë˜ì§€ ì•ŠëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.**


---

### 2.2.2  SVR : C, kernel type, degree 


<d-code language='python'>
param_grid = {
                'kernel' : ['linear', 'poly', 'rbf', 'sigmoid', ],
                'degree' : [1,2,3,4,5,6],
                'C' : [0.5, 1.0, 2.0, 3.0],
                'epsilon' : [0.1, 0.2, 0.3]
            }
</d-code>


<img src="https://drive.google.com/uc?export=view&id=1raHjdlTfaSxx5b7LWsyHLUNXJsl6_ez6" style='width:100%'>

</div>

--- 

## 2.3 Error (prediction - target)

<div class="spanbox" markdown="1" style="width:100%">



###  2.3.1 DT
<img src="https://drive.google.com/uc?export=view&id=1KGjhEqhIJ_k6uZolp-PXGqMGnLyKtRoa" style='width:49%'>
<img src="https://drive.google.com/uc?export=view&id=1MZ1OGvXjHF3U5-LLWZCFA45MB9tYxMlq" style='width:49%'>


### 2.3.2 SVR
<img src="https://drive.google.com/uc?export=view&id=1VOgfS065VeZyBa516uOD3rVlzIC9Z4dD" style='width:49%'>
<img src="https://drive.google.com/uc?export=view&id=1EawHk8Xyg5aObOJnA1umyzjod0pKBSxl" style='width:49%'>

</div>



---

## 3. í•™ìŠµ ë°ì´í„° êµ¬ì„± 

1. **0ê°’ ì½”ë“œ** : ê¸°ì¡´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì½”ë“œì— ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ê°’ì€ (0, í‰ê· , ì¤‘ì•™ê°’) ë“±ì´ ìˆëŠ”ë°, ì •ë„ ì˜ˆì¸¡ ëª¨ë¸ì€ ëª¨ë“  ì½”ë“œì˜ ê°’ì´ ì¡´ì¬í•˜ë©°, ë‹¤ë§Œ ê·¸ ê°’ì´ 0ì¸ ê²½ìš°ì™€ ë™ì¼í•˜ë¯€ë¡œ ìµœì¢…ì ìœ¼ë¡œ 0ì„ ì§‘ì–´ë„£ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤. 
2. **ì •ê·œí™”**: ê¸°ì¡´ ê°’ ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•˜ë¯€ë¡œ, ê°’ì„ ì •ê·œí™”í•˜ì§€ ì•ŠëŠ”ë‹¤. 
3. **ì´ìƒì¹˜ ì œê±°**: ë¬¼ì§ˆì˜ ì–‘ì„ ê·¸ëŒ€ë¡œ ë‚˜íƒ€ë‚´ë¯€ë¡œ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì§€ ì•ŠëŠ”ë‹¤. 
4. ì˜ˆì¸¡ê°’: ê¸°ì¡´ 10000~80000 ë²”ìœ„ì˜ ê°’ì„ 1/10000ë¡œ ì¤„ì—¬ì„œ ì˜ˆì¸¡. 

<div class="spanbox" markdown="1" style="width:100%">
### 3.1 ì˜ˆì¸¡ê°’ ë¶„í¬ 

<img src="https://drive.google.com/uc?export=view&id=16-ZXy2tI6s72_agj7pzy4PTM7IrcB4hd" style='width:100%'>
</div>

<div class="spanbox" markdown="1" style="width:100%">

### 3.2 ì‹¤ì œ ë°ì´í„° ë¶„í¬ / í•™ìŠµë°ì´í„° ë¶„í¬ (0 ê°’ í¬í•¨)

<img src="https://drive.google.com/uc?export=view&id=13cSTKqQQ6W4wb1Mx0PcNAWuwJa0wkrvr" style='width:49%'>
<img src="https://drive.google.com/uc?export=view&id=1L_JVd1oasKDdVA8s23tNF8AsYndP3SpI" style='width:49%'>

</div>



## Appendix: SVR ì„¤ëª… 

* $e^{-\gamma (a-b)^2} $
 * $\gamma$ ê°€ í´ìˆ˜ë¡, ì ë“¤ì´ ê°€ê¹Œìš¸ìˆ˜ë¡ ë” ì ì€ ê°’ìœ¼ë¡œ ëœë‹¤. 
 * (a,b) ì‚¬ì´ê°€ ë©€ìˆ˜ë¡ ê°’ì´ ì‘ë‹¤. (ê°€ê¹Œìš¸ìˆ˜ë¡ í¬ë‹¤.) 
 * [video](https://www.youtube.com/watch?v=Qc5IyLW_hns)
 * after modifying the data distribution, the linear support vectors are fitted. 




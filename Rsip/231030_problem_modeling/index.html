<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | [7] Mathematically modeling SIP </title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="SIP에 대한 수학적인 모델링" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🪴</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/Rsip/231030_problem_modeling/">
    
    <!-- Dark Mode -->
    


    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "[7] Mathematically modeling SIP ",
      "description": "SIP에 대한 수학적인 모델링",
      "published": "October 29, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="sticky-bottom-footer">

    <!-- Header -->    
    <center>
      <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </center>
    <hr> 

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">[7] Mathematically modeling SIP </h1>
        <p>SIP에 대한 수학적인 모델링</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="결론">결론</h2>

<p>기존 Classification 문제는 X, Y의 관계가 존재한다는 가정하에 Y 를 구분하는 X의 특징을 찾는 것을 목표로 한다. 원천 추정 문제는 공통의 특징이 아닌, 생성 위치가 동일하다는 가정이다.
따라서 <strong>원천 정보는 일반적으로 데이터에 없는 특징</strong>이기에 문장와 원천을 관계를 찾아내는 것이 아니라 <strong>문장과 원천을 연결 짓기 방법</strong>을 생성하느 것이다. 이는 문장의 변화를 기준으로 두 가지 방식이 있다.</p>

<ul>
  <li><strong>A) 문장 고정 가정</strong> : 고정된 문장에 대해서 구분된 원천을 추정하는 연구</li>
  <li><strong>B) 문장 변화 가정</strong>  : 문장 변화를 허용하여 원천과 문장을 연결짓는 연구</li>
</ul>

<h4 id="a-문장-고정-가정">A) 문장 고정 가정</h4>

<p>고정된 문장 표현을 GPT에 넣고 원천을 구분할 수 있는 특징이 있다는 가정하에 <strong>여러 원천들을 맵핑 시키는 분류 학습 연구.</strong> 
문장 $X$ 와 원천 $S$에 대해서 Joint distribution $P(X, S)$ 에서 $P(S|X)$ 를 유도하는 과정.</p>

<ol>
  <li>X에 원천이 구분되는 특징이 <strong>명확하게 있는</strong> 경우 : Classification 학습으로 해결 가능</li>
  <li>X에 원천이 구분되는 특징이 <strong>일부 있는</strong> 경우 : 최소한의 구분되는 특징으로 Classification 학습</li>
  <li>X에 원천이 구분되는 특징이 <strong>없는</strong> 경우 : Classification 학습 불가능.</li>
</ol>

<h4 id="b-문장-변화-가정">B) 문장 변화 가정</h4>

<p>문장과 원천은 관계가 없다. 관계를 생성하기 위해서 문장 변화 방법은 워터마크처럼 문장을 변화하여 문장과 원천을 연결짓는다. 
Joint distribution $P(X, S)$ 에서 $P(\hat{X}, S)$ 로 모델링을 바꾸는 과정.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">원천:James's 일기, 나는 밥을 먹었다</code> (direct  source)</li>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">원천:EJRF, 나는 밥을 먹었다</code> (hash type source)</li>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">나는 밥을 꽤나 먹었다</code> (invisible, watermark)</li>
</ul>

<hr />

<blockquote>
  <p>원천은 없는 정보지만, 필요한 정보이다.</p>
</blockquote>

<blockquote>
  <p>기존 Classification 문제는 X, Y의 관계가 존재한다는 가정하에 Y 를 구분하는 X의 특징을 찾는 것을 목표로 한다. 원천 추정 문제는 공통의 특징이 아닌, 생성 위치가 동일하다는 가정이다. 따라서 $X$ 에 클래스를 구분하는 특징이 없을 수 있다.</p>
</blockquote>

<p>따라서 연구 방향은 원천을 구분할 수 있는 특징의 수준에 따라서 나뉜다.</p>
<ol>
  <li>X에 원천이 구분되는 특징이 <strong>있는</strong> 경우 : Classification 학습으로 해결 가능</li>
  <li>X에 원천이 구분되는 특징이 <strong>일부 있는</strong> 경우 : 최소한의 구분되는 특징으로 Classification 학습</li>
  <li>X에 원천이 구분되는 특징이 <strong>없는</strong> 경우 : Classification 학습 불가능.</li>
</ol>

<p>문장 X에 대해서 주어진 원천 $S_X$ 에 대하여, 강제적으로 joint P(X,S) 를 형성하는  방식을 찾는다.<br />
원천소스 추정의 문제는 문장 $X$ 와 원천 $S$ 에 대해서 다음과 같은 $P(X,S)$ 를 모델링 하는 것이다.</p>

\[\begin{gather*}
\operatorname{maximize} P(X, \hat{S}), \hat{S}=S_X  \\
\operatorname{minimize} P(X, \tilde{S} ), \tilde{S} \ne S_X 
\end{gather*}\]

<p>문장 X와 함께 주어진 원천 혹은 겹치는 경우 원천들을 나타내는 $S$ 에 대해서 joint 를 최대화하면서 해당하지 않는 원천들에 대해서는 확률을 최소화하는 문제이다. 
더 나아가서 GPT 모델의 원천을 찾는 문제는, 모델에 문장과 모델의 관계는 모델 $\theta$ 에 문장 $X$ 를 넣어서 도출된 표현 $H=H(X;\theta)$ 와의 joint를 학습하는 문제로 변환된다.</p>

\[\begin{gather*}
\operatorname{maximize} P(H, \hat{S}), \hat{S}=S_{H}  \\
\operatorname{minimize} P(H, \tilde{S} ), \tilde{S} \ne S_{H}
\end{gather*}\]

<ul>
  <li>문장의 표현을 탐구하여, 원래 원천과의 관계성을 학습시키는 연구 분야. 이를 통해, 해당 문장이 모델에 대해서 해당 원천이라고 추정되어야 하는 이유를 찾는 연구.</li>
</ul>

<h3 id="원천-워터마크-문장-변화-가정">원천 워터마크 (문장 변화 가정)</h3>

<p>워터마크는 제 3자에게 보이지 않는 정보를 숨기는 경우이다. 정보를 숨기기 위해서 문장의 변경이 가능하다. 
워터마크 연구는 문장 $X$ 변화가 자유롭다. 따라서 워터마크를 숨기고, 숨겨진 워터마크를 다시 찾아내는 형태이다. 이를 원천 추정에 적용하면,</p>

<ol>
  <li>원천이 동일해지도록 문장을 변경한다.</li>
  <li>원천이 동일해지도록 문장 표현을 변경한다. (hidden)</li>
</ol>

<p>이러한 경우는 문장 혹은 문장표현을 강제적으로 바꿔서 원천이 표시되도록 나타내는 방법이다. 가장 단순한 형태는 원천의 링크를 문장에 표현하는 것이다.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">원천:James's 일기, 나는 밥을 먹었다</code> (direct  source)</li>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">원천:EJRF, 나는 밥을 먹었다</code> (hash type source)</li>
  <li><code class="language-plaintext highlighter-rouge">나는 밥을 먹었다.</code> –&gt; <code class="language-plaintext highlighter-rouge">나는 밥을 꽤나 먹었다</code> (invisible, watermark)</li>
</ul>

<blockquote>
  <p>원천소스 문제는 X에 Y를 구분하는 특징이 없는 경우가 허다하다. 이 경우, $X \Rightarrow \hat{X}$ 로 변경하여 원천을 결합해야 한다. 그러나 이 문제는, 원천을 안다는 가정이다.</p>
</blockquote>

<hr />

<p>$X$에 원천 $S$ 의 표현을 강제적으로 주는 경우, 원천을 주고, 원천을 찾는 형태이다. 이는 정답을 주고 정답을 찾으라는 경우이다. 따라서 제대로 된 문제가 아니다.</p>

<h2 id="introduction">Introduction</h2>

<p>기존 원천소스 추정 문제를 명확한 분류 문제로 설계하는 것은 잘못되었다 <d-footnote> 명확하다는 말의 의미는 정확한 레이블을 찾는 문제를 말한다. 이와는 다르게 원천 소스 맵핑 문제는 멀티레이블이다.  </d-footnote> 대신에 원천 소스 추정문제는 멀티레이블적인 성격을 띄며, 해당 원천으로서 특징을 가지고 있는지 아닌지 판단하는 문제이다. 따라서 기존 Extreme Classification (EC) 문제라고 했던 것보다는 Extreme Multi-label Classification (XML) 문제이다. 단, XML에서 해당 레이블의 특징을 가지고 있다는 가정은 원천 소스 문제에서는 성립하지 않을 수 있다. 왜냐하면 원천으로 추정된 문장들은 서로 어떠한 공통된 특징이 없을 수 있기 때문이다. <strong>원천소스에 맵핑이 된다는 사실</strong>은 존재하지만, 맵핑이 되는 기준이 세워지지 않았던 것이다. 이에 본 연구에서는 <strong>문장이 원천소스에 맵핑이 된다는 사실이 정확하게 무엇을 나타내는지</strong> 연구한다.</p>

<hr />

<p>Thoughts</p>

<hr />

<p>Thoughts</p>

<hr />

<p>Thoughts</p>

<hr />

<h2 id="분포">분포</h2>

<p>원천소스 $S$ 와 문장 $X$ 에 대한 관계는 두 변수의 joint distribution $ p(S, X) $으로 나타낼 수 있다. 원천소스에 해당하는 문장들이 있고, 이 문장은 원천 소스와 관련되어 있다. 
생성모델의 원천소스를 추정한다는 말은 학습 데이터 혹은 생성된 문장 $X$에 대해서 그 원천 $P(S|X)$ 을 모델링 하는 것이다. Pretraining 단계에서는 문장에 대한 출처가 확실하기 때문에 $P(S=s_X | X) = 1$ 을 만족하는 것처럼 보이지만, 동일한 문장이 다른 두 원천 $s_X$와 $s’_X$에 존재할 수 있으므로 $P(S=s_X | X) = 1/2$ 와 $P(S=s’_X | X) = 1/2$ 으로 확률이 달라진다. 물론 대부분의 문장은 sparse 하기에, <d-footnote> (NLP 성질, 단어 확인 필요) </d-footnote> $p(S|X)$ 의 확률 분포는 낮은 엔트로피를 가진다. 파라미터 $\theta$ 를 가지는 예측 GPT 모델에 대해서 원천을 추정하는 $P(S|H(X;\theta))$  경우는 단순히 문장이 아니라 문장에 대한 표현 $H$ 이며, $P(S|X)$ 와는 추론에서 큰 차이를 보인다.</p>

<h3 id="ps-x-혹은-ps-h">$P(S, X)$ 혹은 $P(S, H)$</h3>

<p>원천과 문장을 모델링하는 $P(S,X)$ 와 다르게, $P(S,H)$는 원천과 문장의 표현 벡터의 관계를 모델링한다. 
다음 단어에 대한 선호도로부터 원천을 추정하는 것이다.</p>

<ul>
  <li>원천의 데이터다</li>
  <li>원천에 대해서 구분되는 특징이 있다.</li>
  <li>원천의 특징이 있다.</li>
  <li>원천을 추가한다.  $P(S, H)$</li>
</ul>

<p>원천 guided generation.</p>

<hr />

<p>텍스트로부터 원천에 대해서 명확하게 찾을 수 없다면, 우리가 모델링 해야 하는 부분은 텍스트와 원천의 join distribution 이다.</p>

<h2 id="가정들">가정들</h2>

<p>문장과 레이블 데이터에 대한 학습에서 원천소스 맵핑 가능의 가정은 다음과 같다.</p>

<ol>
  <li>원천소스 구분 표현 존재의 가정 : 주어진 문장 혹은 문장 표현이 원천을 구분할 수 있는 특징이 있다.</li>
  <li>불합리한 특징의 가정</li>
  <li>추가 방향성 표현의 가정</li>
</ol>

<h3 id="원천소스구분-표현-존재의-가정">원천소스구분 표현 존재의 가정</h3>

<p>문장 $x = (x_1, x_2, \cdots, x_T)$에 대한 임베딩 $e = (e_1, e_2, \cdots, e_T)$ 로부터 생성되는 심층 표현 $h = (h_1, h_2, h_T)$가 주어졌을 때, 
심층 표현은 문장에 대한 모델의 해석으로, 문장에 대한 정보를 담고있다. 이로부터 유하한 원천 소스 셋 $S = [N_s]$ 에 대한 원천 소스 추정 문제는 다음과 같이 쓰인다.</p>

\[\hat{s} = \arg\max_s p(S|h)\]

<p>심층 표현으로부터 원천 소스를 추정하는 경우 가정은 다음과 같다.</p>

<blockquote>
  <p style="font-style:normal"> (표현 포함의 가정) </p>
  <p>심층 표현은 원천소스를 구분할 특징을 내보하고 있다.</p>
</blockquote>

<p>해당 가정은 문장 표현 자체가 원천소스를 추정하기 충분하다는 가정이다.</p>

<hr />

<h3 id="불합리한-특징의-가정">불합리한 특징의 가정</h3>

<p>원천소스 구분 문제에서</p>

<ol>
  <li>원천 내에서 특징이 너무 많으며, 원천들은 특징을 공유한다.</li>
  <li>동일한 문장이 서로 다른 원천에서 자주 등장한다.</li>
</ol>

<p>두 원천의 고유한 특징 혹은 concept 을  $F = (f_1, f_2, \cdots, f_N) $ 과 $G = (g_1, g_2, \cdots, g_N)$ 라고 하면, 
두 원천을 구분하는 특징의 개수는 교집합을 활용하여 쓸 수 있다.</p>

\[\vert F \cap G  \vert\]

<p>그러나 동일한 원천 내에서 $F$ 가 아예 존재하지 않을 가능성이 있다. 임의의 $f$ 특징이 $F$에 존재한다면, 원천 내에 $f$ 가 존재하지 않는 특징을 넣으면 되기 때문이다. 
예를 들어서, 사람과 강아지를 분류할 때, 뾰족한 귀의 유무라면, 귀가 찍히지 않은 강아지 샘플을 넣어서 귀라는 특징으로 분류되는 경우가 막힐 수 있다. 
원천소스 추정에서는 원천소스를 구분하는 명확한 특징들이 다른 곳에서도 나타날 수 있다.</p>

<ul>
  <li>원천 A 내용 : 해리포터에 대한 설명</li>
  <li>원천 B 내용 : 해리포터를 좋아하는 이유</li>
  <li>원천 C 내용 : 해리포터 개봉일에 대한 정보</li>
</ul>

<p>원천소스는 두 가지 특징을 가지고 있고, 이는 Classification의 해결 가능성에 의문을 제시한다.</p>

<ol>
  <li>원천 내에 다양한 특징이 존재할 수 있다. (다중 특성 암기 필요)</li>
  <li>서로 다른 원천 소스들의 특징은 겹칠 수 있다. (분류 불가능성)</li>
</ol>

<p>그러므로 아래 방식으로 원천소스를 추정하는 것은 잘못 정의되었을 가능성이 높다.</p>

\[\hat{s} = \arg\max_s p(S|h)\]

<hr />

<h2 id="원천은-선택하는-것이다">원천은 선택하는 것이다.</h2>

<p>텍스트로부터 원천에 대해서 명확하게 찾을 수 없다면, 우리가 모델링 해야 하는 부분은 텍스트와 원천의 join distribution 이다. 
\(p(S, X)\)</p>

<p>실용적으로 모델링 하는 것은</p>

<p>원천에 대한 문장의 확률 $P(X|S)$ 및 문장에 대한 원천의 확률이다. $P(S|X)$ 따라서 명확한 문제는 classification 이 아니라 distribution matching이다. 
원천을 추정한다는 것은,</p>

<table>
  <tbody>
    <tr>
      <td>$P(S</td>
      <td>X) = \frac{P(X</td>
      <td>S) P(S)}{p(X)}$를 계산하는 것이다.</td>
    </tr>
  </tbody>
</table>

<hr />

<p>원천에 대한 선호 prior $p(S)$로부터 샘플된 원천에 대한 표현을 생성하여 원천을 입력으로 주는 방식이다.</p>

\[s \sim p(S)\]

<p>원천에 대한 샘플링으로부터 방향 벡터 $v_s$ 를 얻으면 해당 정보는 심층 표현에 인코딩 된다.</p>

\[p(x|h + v_s) \approx p(S|h)\]

<p>기존 LLM의 표현을 유지하면서 원천을 복원하면서 된다.</p>

<p>\(\max \ell(p(x|h + \hat{v}_s), p(x|h) ) - \alpha \ell(s, \hat{s})\)
첫번째 텀은 원천 소스 표현을 집어 넣을지라도 단어 복원을 그대로 진행하는 경우이다. 
두 번째 텀은 추정된 원천 $\hat{s} = g(h + \hat{v}_s)$ 을 복원하는 것이다.</p>

<p>해당 Objective 는 원천소스 인코딩을 진행하면서 원천소스 복원을 그대로 진행한다.</p>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>


      <hr>
<!----></div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        &copy; Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>

  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>

    <center>
        <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </center>
    <hr> 

</html>

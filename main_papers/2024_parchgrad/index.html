<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini |  ParchGrad: Controlled Internal Gradients for Reliable Saliency Map <strong> [Preprint] </strong></title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="We prune gradient signals in convolutional layer while preserving the variance of gradient magnitudes to balance interaction between combined modules. We propose ParChGrad to obtain more reliable saliency map!" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/main_papers/2024_parchgrad/">
    
    <!-- Dark Mode -->
    

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": " ParchGrad: Controlled Internal Gradients for Reliable Saliency Map <strong> [Preprint] </strong>",
      "description": "We prune gradient signals in convolutional layer while preserving the variance of gradient magnitudes to balance interaction between combined modules. We propose ParChGrad to obtain more reliable saliency map!",
      "published": "November 15, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="https://fxnnxc.github.io/" style="margin-left:20px ;">
              <!--Bumjini-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">Bumjini    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->
              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_papers/"> Papers</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_articles/"> Articles</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_projects/"> Projects</a>
              </li>

              <!-- Other pages -->
              <li style="font-size: 17px" class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Others</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/side_papers/">üóÇÔ∏è side-paper</a>
                  <a class="dropdown-item" href="/side_articles/">ü•ï side-articles</a>
                  <a class="dropdown-item" href="/book/">üìö book (korean)</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;"> ParchGrad: Controlled Internal Gradients for Reliable Saliency Map <strong> [Preprint] </strong>
</h1>
        <p>We prune gradient signals in convolutional layer while preserving the variance of gradient magnitudes to balance interaction between combined modules. We propose ParChGrad to obtain more reliable saliency map!</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <p><strong>ParchGrad: Controlled Internal Gradients for Reliable Saliency Map üöÄ</strong></p>
<div class="authors">Bumjin Park, Giyeong Jeon, and Jaesik Choi, 2023  
</div>
<h3 class="demo-title"> TDLR; </h3>
<div style="display: grid;grid-template-columns: 1fr 1fr;border:1px solid #DDDDFF;border-radius:10px;padding:10px;align-items:center;">
    <div>
    <ul>
    <li> <strong> Motivation </strong> : Gradients are shattered, and more refined internal signals can improve the saliency map. </li> 
    <li> <strong> Problem </strong> : Comparison of internal gradients in a convolutional layer and make a measure properly compare gradient signals.  </li>
    <li> <strong> Method </strong> : We propose $\gamma$-dominance based on the random variable formulation of gradients. </li>
    <li> <strong> Contribution </strong> : We propose variance conservation and class-wise channel selection to safely prune internal gradient signals. </li>
    <li> <strong> Keywords </strong> : saliency map, channel pruning </li>
    </ul>
      </div>
  </div>

<center>
  <div class="demolink" style="padding-bottom:1rem;padding-top:0.5rem;">
    <a class="box-demo-link" href="https://drive.google.com/file/d/1E_7MIQFcM3livmezMwD1fHmz6gwHm4j1/view?usp=drive_link" style="background:#AA00AA" target="_blank" rel="noopener noreferrer">Pre-print (currently google drive)</a>  
      <a class="box-demo-link" href="https://github.com/fxnnxc/Parchgrad" style="background:#000000;" target="_blank" rel="noopener noreferrer">Code</a> 
    <a class="tooltip-wrap">
      <span class="tooltip-span"> Abstract </span>
      <div class="tooltip-content" style="line-height:1.0rem"> 
      <strong> Abstract </strong> <br>
      Explaining the decision of neural networks is crucial to ensure their reliability in various image tasks. Among several input attribution methods, the saliency map explains the decision with the propagated gradients on pixels. One of the fundamental problems of the saliency map is gradient shattering which leaves noise on pixels and hinders the interpretation of attribution maps. To provide a clear explanation, controlling the internal gradient signals is essential. However, to the best of our knowledge, there is no work on modifying the internal gradient signals so that the saliency map provides reliable explanations. To initialize the control of internal gradient signals in the saliency map, we provide theoretical analysis on the controllable modification of gradients in multiple convolutional channels and propose ParchGrad, which prunes channels by partitioning multiple channels into two groups. In addition, we propose a class-wise selection method based on statistical tests to select which channels to magnify or reduce the impact of gradients.
      </div>
    </a> 
  </div> 
    </center>

<h2 id="visualization-of-parchgrad-vs-gradient">Visualization of ParchGrad vs Gradient</h2>

<div style="border:1px solid #DDDDFF;border-radius:10px;padding:10px;">
<center>
<img src="https://github.com/fxnnxc/parchgrad/blob/main/labs/visualize/13220.gif?raw=true" style="width:100%">
<img src="https://github.com/fxnnxc/parchgrad/blob/main/labs/visualize/797.gif?raw=true" style="width:100%">
<img src="https://github.com/fxnnxc/parchgrad/blob/main/labs/visualize/16298.gif?raw=true" style="width:100%">
</center>
</div>

<h2 id="introduction">Introduction</h2>

<p>Explaining the decision of neural networks is crucial to ensure their reliability in various
image tasks. Among several input attribution methods, the saliency map explains the
decision with the <strong>propagated gradients on pixels</strong>. One of the fundamental problems
of the saliency map is gradient shattering which <strong>leaves noise on pixels and hinders the interpretation of attribution maps</strong>.</p>

<p>To provide a clear explanation, controlling the internal gradient signals is essential. However, to the best of our knowledge, there is
no work on <strong>modifying the internal gradient signals</strong> so that the saliency map provides
reliable explanations.</p>

<p>To initialize the control of internal gradient signals in the saliency
map, we provide theoretical analysis on the controllable modification of gradients in
multiple convolutional channels and propose ParchGrad, which prunes channels by
partitioning multiple channels into two groups. In addition, we propose a class-wise
selection method based on statistical tests to select which channels to magnify or
reduce the impact of gradients.</p>

<center>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211231&amp;authkey=%21AFo75M5GaaMDuvw&amp;width=1866&amp;height=730" style="width:100%">
</center>

<h3 id="contribution-comparison-with-other-explainable-methods">Contribution: Comparison with other explainable methods.</h3>

<table>
  <thead>
    <tr>
      <th>Method¬†</th>
      <th>Category</th>
      <th style="text-align: center">All layers</th>
      <th style="text-align: center">Prune Channels</th>
      <th style="text-align: center">#Propagation*</th>
      <th style="text-align: center">Sample Size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ScoreCAM <d-cite key="wang2020score">  </d-cite>
</td>
      <td>CAM</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O(C)</td>
      <td style="text-align: center">O(C)</td>
    </tr>
    <tr>
      <td>AblationCAM <d-cite key="ramaswamy2020ablation">  </d-cite>
</td>
      <td>CAM</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O(C)</td>
      <td style="text-align: center">O(C)</td>
    </tr>
    <tr>
      <td>LRP  <d-cite key="bach2015pixel">  </d-cite>
</td>
      <td>LRP</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td>CRP <d-cite key="achtibat2022towards">  </d-cite>
</td>
      <td>LRP</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td>Gradient <d-cite key="adebayo2018sanity">  </d-cite>
</td>
      <td>Saliency</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td>InputGrad <d-cite key="adebayo2018sanity">  </d-cite>
</td>
      <td>Saliency</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(1)</td>
    </tr>
    <tr>
      <td>Integrated Gradient <d-cite key="sundararajan2017axiomatic">  </d-cite>
</td>
      <td>Saliency</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(M)</td>
    </tr>
    <tr>
      <td>SmoothGrad <d-cite key="smilkov2017smoothgrad">  </d-cite>
</td>
      <td>Saliency</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">X</td>
      <td style="text-align: center">O(M)</td>
      <td style="text-align: center">O(M)</td>
    </tr>
    <tr>
      <td><strong>ParchGrad (proposed)</strong></td>
      <td>Saliency</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O</td>
      <td style="text-align: center">O(1)</td>
      <td style="text-align: center">O(1)</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
<strong>‚ÄúAll Layers‚Äù</strong> refers to whether including most of convolutional layers in a model for the explanation,</li>
  <li>
<strong>‚ÄúPruning‚Äù</strong> refers to whether manual modification is applied,</li>
  <li>
<strong>‚ÄúPropagation‚Äù</strong> is the complexity of individual back-propagation to obtain the explanation.</li>
  <li>
<strong>‚ÄúSample-size‚Äù</strong> is the total number of samples to obtain the explanation.</li>
</ul>

<h2 id="problems">Problems</h2>

<h3 id="1-gradients-are-noisy">1. Gradients Are Noisy</h3>

<p>Gradients are noisy to be interpreted as large number of small signals could exists on a input. A toy experiment below shows the impact of noisy gradients, which are randomly distributed.</p>

<center>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211233&amp;authkey=%21AHInAoRba6oIE1s&amp;width=1024" style="width:100%">
</center>

<p>Let $\mathcal{H}$ be a group of 10  random gradients whose first entry is sampled from $\mathcal{N}(0, 0.1)$ and the second entry is sampled from $\mathcal{N}(0.0, 1.0)$ and $\mathcal{L}$ be a group of 100 random gradients  whose elements are both sampled from  N(0, 0.1). The summed vector in each group and the combined group is shown in Figure below. Although H group is dominant in Dim2 (0,1), the summed vector of L group is dominant in Dim1 (1,0)  because of large number of vectors. Consequently, the final direction is (1,1) direction (black). This experiment shows the impact of large number of irrelevant channels (red).</p>

<h3 id="2-zero-pruning-of-gradients-result-in-artifacts">2. Zero Pruning of Gradients Result in Artifacts</h3>

<p>One trivial method to remove noisy gradients is to set zero. However, we observe that the zero gradient signals on selected channels results in artifacts.</p>

<center>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211232&amp;authkey=%21AGrj9LB69JwcO18&amp;width=2926&amp;height=944" style="width:100%">
</center>

<p>The artifacts are due to the fact that multiple multiple modules are interact to make gradient signal. When zero pruning is applied to the gradients in a convolutional layer, the impact of the convolutional layer is <strong>reduced</strong> and lost the dominance over other modules.</p>

<h2 id="methods--gamma-dominance-and-variance-conservation">Methods : $\gamma$-dominance and variance conservation</h2>

<p>To theoretically understand the pruning and impact of gradients, we define $\gamma$-dominance and provides theorems to preserve the magnitude of the gradients. Please see the paper for the detailed definition and the theorems.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Gradient signal is crucial in explainable AI for various reasons including training and explaining. As the saliency map is model-agnostic, gradient signals are the first option to explain models. However, as gradients are noisy, users cannot believe easily whether the attribution is reliable. To provide a more reliable saliency map, tackling the internal mechanism of gradients and controlling the signals is essential. This paper provides a theoretical and empirical analysis of the gradients so that the XAI community can clarify how the gradients impact the saliency map and how to control them. In detail, this paper shows the impact of variance over many channels and provides a solution to safely turn off the channel impact while conserving the magnitude with other modules.</p>

<p>We also propose class-wise channel selection, which selects channels based on the statistical importance of GAP. This selection could be understood as adding a forward bias in the backward (adding activation information to gradient computation). We acknowledge that class-wise selection bias is not the best option, but possibly a good option when there is no knowledge of channels. For the ongoing research, we will study other channel selection methods, such as CLIP-based or circuit-based channel selection, so that constructing proper channel propagation paths improves the explainability of the saliency maps.</p>

<p>We believe ParchGrad can broaden the overall understanding of saliency maps in many image application fields where obtaining a reliable saliency map is important.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--
    </div>
 -->
      <hr>
<div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;">
    <script>
      let giscusTheme = localStorage.getItem("theme");
      let giscusAttributes = {
          "src": "https://giscus.app/client.js",
          "data-repo": "fxnnxc/fxnnxc",
          "data-repo-id": "MDEwOlJlcG9zaXRvcnkzMjQ2NjUxMTU=",
          "data-category": "Q&A",
          "data-category-id": "DIC_kwDOE1n_G84CYOk_",
          "data-mapping": "title",
          "data-strict": "0",
          "data-reactions-enabled": "1",
          "data-emit-metadata": "0",
          "data-input-position": "top",
          "data-theme": giscusTheme,
          "data-lang": "en",
          "crossorigin": "anonymous",
          "async": "",
      };
  
  
      let giscusScript = document.createElement("script");
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById("giscus_thread").appendChild(giscusScript);
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by giscus.</a>
</noscript>
  </div>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  <center>
    <a  href="">
    <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </a>
  </center>
  <hr> 

  </html>

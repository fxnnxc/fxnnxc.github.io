---
layout: distill
authors: 
    - name: Bumjin Park
      affiliations:
        name: KAIST
bibliography: all.bib
giscus_comments: true
disqus_comments: true
date: 2023-08-4
featured: true
title: 'Neuron in Neuroscience and Deep Learning'
description: ''
---

## Introduction 

There are several attempts to understand human in the fields of biology, neuroscience, ethology, and philosophy. Especially, neuroscience interprets human with neurons in a brain. Neurons in a brain process massive information and the intelligence increases as the number of neurons increases. However, understanding the general role of a single neuron is hardly discovered as we can not test the neuron separately excluding other neurons. However, unlike the neurons in neuroscience, neurons in deep learning could be tested easily as we can debug the network. Recent studies have shown the role of individual neurons in both vision and NLP domains and we can understand the interaction between neurons well. If the neurons in our brain compute and  process the signals with the neurons in deep learning, we can further understand neurons in both field. To do this, we should know how similar neurons in neuroscience and deep learning are. 

The reason why I wrote this post, even though I studied deep learning, is that understanding the neurons in neuroscience can further helps to reveal the mechanisms of neurons in deep learning. To components are similar to each other, but have distinct difference such as learning processes. We study the question **How much neurons are similar in both fields?** Before answering this question we should answer this question. **What is neurons in deep learning?**

## Neuroscience

Human body has cell and there are cells called **neuron** whose role is the transmission of signals.  Neurons communicate each other by chemical materials called 
**synapse** which is the connection part between two neurons. In human brain, there are 860B number of neurons and a single neuron has 7,000 synapses. Therefore, human brain has 6 trillion synapses. 

$$
\begin{gather}
\text{Number of Neurons} \times \text{Number of Synapses per a neuron} \approx \text{Total number of synapses} \\ 
\Rightarrow 860 \text{B} \times 7,000 \approx 6 \text{trillion}
\end{gather}
$$

The number of synapses is the number of connections and the neurons has information in it. When a single neuron is fired, we can consider the successively fired neurons like a chain. Consider the following example.  

1. Eyes get light signals (**Dog image** ğŸ¦®)  
2. neurons in eyes are fired and signal is transmitted to the neurons in the brain (**Neurons related to vision** ğŸ‘€)
3. Several neurons in a brain are affected by the vision neurons
  * Emergence of vocabulary "dog" (**Dog Neuron** ğŸ¶)
  * Emergence of vocabulary "cat" by "dog" (**Cat Neuron** ğŸ˜¸)
  * Prediction of the dog movement (**Future Prediction Neuron** âŒ›ï¸)
  * Emergence of traumas related to a dog (**Long-term Memory Neuron** ğŸ¾)
  * Trauma makes me feel bad (**Emotion Neuron** ğŸ˜¢)

Note that even though we only observed the dog image, other neurons related to the **dog**  are fired. Understanding the circuits of neurons are like finding such consequent events of neurons. 

---

### Neuron

> These videos can help your understanding of neurons
<div>
<iframe width="340" height="315"
src="https://www.youtube.com/embed/SczOfOXY17U">
</iframe>
<iframe width="340" height="315"
src="https://www.youtube.com/embed/GIGqp6_PG6k">
</iframe>
</div>

#### Basic Structure

Neurons communicate with each other with chemical materials such as Na+ and Cl-, and process the signal in terms of electricity. To understand this communication process, lets see what components a neuron has. 


<figure style="text-align:center; display:block;" >
<img src="/assets/kor/neurons_as_neurons/neuron.png" style="width:100%">
<figcaption>
Figure. Basic structure of a neuron. The dendrite receives input chemical, axon transfers the electricity, and axon terminal outputs chemical material again. 
</figcaption>
</figure>

* `Dendrites` : Obtains chemical materials from other neurons (receiver)
* `SOMA` (Nuclear) : The nuclear of a neuron
* `Axon` : connects `Dendrites` and `Axon Terminal` and transfers the electrical signal.
* `Axon Terminals` : transmits chemical materials to other neurons (publisher)

#### Communication 

A neuron is normally a negative state (-70mv) and if a `Dendrite` receives negative ion, the state is still negative. On the other hand, if `Dendrite` receives positive ions such as $Na^{+}$, the dendrite part becomes positive state. Then, the electricity flows from `Dendrite` to `Axon Terminal` in a neuron to make `Neutral Charge Equilibrium` state. The pipe for the transmission is called `Axon` and the leaf part is `Axon Termnial`. When the `Axon Terminal` becomes positive state, neurotransmitters are spread. 

<figure style="text-align:center; display:block; grid-column:middle;">
<img src="/assets/kor/neurons_as_neurons/neuron_state.png" style="width:180%">
<figcaption>
  How a neuron transmits electrical signal from dendrites to axon terminals. Neuron is basically negative state (-), the activated part are relatively positive state (+). 
</figcaption>
</figure>

In summary, a successive propagation of chemical makes the communication. 

### Synapse

> âš ï¸ ì‹œëƒ…ìŠ¤ì— ëŒ€í•œ ì´í•´ëŠ” ë‰´ëŸ°ì˜ ì˜ì‚¬ì†Œí†µì„ ëª…í™•í•˜ê²Œ ì´í•´í•˜ëŠ”ë° í•„ìš”í•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ê³¼ ë¹„êµë¥¼ ìœ„í•´ì„œ ë°˜ë“œì‹œ í•„ìš”í•˜ì§„ ì•Šë‹¤. ìš”ì•½í•˜ìë©´, **ë‰´ëŸ°ì´ ì—¬ëŸ¬ ë‰´ëŸ°ë“¤ì˜ ê°’ì„ ì¢…í•©í•˜ì—¬ í™œì„±í™”ë¥¼ ê²°ì •í•˜ê³  í•´ë‹¹ ë‰´ëŸ°ì€ ë‹¤ìŒ ë‰´ëŸ°ì— ê°’ì„ ì „ë‹¬í•œë‹¤ëŠ” ê²ƒì´ë‹¤.**ëŠ” ê²ƒì´ë‹¤. ì´ ì¥ì€ TMIì¼ ê°€ëŠ¥ì„±ì´ ìˆì–´ì„œ, ë¶ˆí•„ìš”í•œ ì‚¬ëŒì€ 2-3 ì‹ ê²½í•™ì  ì‹ í˜¸ì „ë‹¬ì²´ê³„ë¡œ ë„˜ì–´ê°€ë„ ì¶©ë¶„í•˜ë‹¤. 

ì •ë³´ë¥¼ ë°›ëŠ” ë‰´ëŸ°ì—ê²ŒëŠ” Dendrite ê°€, ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ë‰´ëŸ°ì—ëŠ” Axon Terminal ì´ ê´€ì—¬í•˜ë©° ì´ ë‘ê°€ì§€ê°€ ì—°ê²°ëœ ë¶€ë¶„ì„ `ì‹œëƒ…ìŠ¤`ë¼ê³  ë¶€ë¥¸ë‹¤. 
ë”°ë¼ì„œ ì‹œëƒ…ìŠ¤ëŠ” ë‘ ê°œì˜ ë‰´ëŸ°ì´ ì—°ê²°ë˜ì–´ ë°œìƒí•˜ëŠ” ì§€ì ì´ë©°, ì‹ í˜¸ë¥¼ ì „ë‹¬í•´ì£¼ëŠ” ìª½ê³¼ ë°›ëŠ” ìª½ì„ êµ¬ë¶„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ë¶€ë¥¸ë‹¤.  `N: ë‰´ëŸ°, [*] ë‰´ëŸ°ì— ì—°ê²°ë˜ëŠ” ë‹¤ë¥¸ ë‰´ëŸ°ë“¤.` 
* **(ì¢Œ) Presynaptic Neuron** : `Axon Terminal`ë¡œ ì‹ í˜¸ë¥¼ ì „ë‹¬ **í•˜ëŠ”** ë‰´ëŸ°  $(N \rightarrow \[*\])$
* **(ìš°) Postynaptic Neuron** : `Dendrite`ìœ¼ë¡œ ì‹ í˜¸ë¥¼ ì „ë‹¬ **ë°›ëŠ”** ë‰´ëŸ° $$([*] \rightarrow N)$$

<figure style="text-align:center; display:block;width:100;" >
<img src="/assets/kor/neurons_as_neurons/synapse.png" style="width:100%">
<figcaption>
  Figure. ë‘ ë‰´ëŸ°ê³¼ ì´ë“¤ì˜ ì—°ê²°ë¡œ ì¸í•´ì„œ ìƒê¸°ëŠ” ì‹œëƒ…ìŠ¤. ì‹ í˜¸ë¥¼ ì£¼ëŠ” ìª½ì€ axon terminalì„ í†µí•´ì„œ, ë°›ëŠ” ìª½ì€ dendriteì„ í†µí•´ì„œ í†µì‹ í•œë‹¤. 
</figcaption>
</figure>

#### Aggregation of Received signal

í•˜ë‚˜ì˜ ë‰´ëŸ°ì´ ì „ë‹¬í•˜ëŠ” ì „ê¸°ì  ìƒíƒœëŠ” ë‹¨ìˆœíˆ (+) í˜¹ì€ (-) ì´ì§€ë§Œ ë‰´ëŸ°ì´ ë°›ëŠ” í™”í•™ë¬¼ì§ˆì€ ì—¬ëŸ¬ ê°œì˜ ë‰´ëŸ°ë“¤ì´ ë³´ë‚´ëŠ” ì •ë³´ê°€ `Dendrites` ì— ì·¨í•©ëœë‹¤. ë”°ë¼ì„œ, ì—¬ëŸ¬ ë‰´ëŸ°ì˜ ì „ê¸°ì  ì‹ í˜¸ì˜ í•©ì´ ìµœì¢…ì ìœ¼ë¡œ `Axon` ì„ í†µí•´ì„œ ì „ë‹¬í•˜ëŠ” ì „ê¸°ì  ì‹ í˜¸ë¡œ ìƒê°ë  ìˆ˜ ìˆë‹¤. ì´ëŠ” ê° Dendrite ë“¤ì´ ì „ë‹¬ë°›ì€ ìŒì´ì˜¨ ë˜ëŠ” ì–‘ì´ì˜¨ì˜ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ (Neurotransmitters) $T_1, T_2, \cdots$ ë¡œë¶€í„° ì „ê¸°ì  ì‹ í˜¸ê°€ ê²°ì •ë¨ì„ ë‚˜íƒ€ë‚¸ë‹¤. 

$$
\text{ì „ê¸°ì  ì‹ í˜¸} = T_1 + T_2 + T_3 + T_4 + \cdots
$$

<figure style="text-align:center; display:block;width:100;" >
<img src="/assets/kor/neurons_as_neurons/transmission.png" style="width:100%">
<figcaption style="text-align:left">
  Figure. (ìœ„) ë‰´ëŸ°ì˜ Dendrites ì— ì—¬ëŸ¬ ê°œì˜ ë‰´ëŸ°ì´ ì‹ í˜¸ë¥¼ ë³´ë‚´ê³ , ìµœí•©ëœ ì •ë³´ëŠ” ì „ê¸°ì  ì‹ í˜¸ë¡œ ìš°ì¸¡ì— ë„ë‹¬í•œë‹¤. (ì•„ë˜) Axon Terminalì´ ì–‘ì „í•˜ ìƒíƒœê°€ ë˜ë©´ í™”í•™ë¬¼ì§ˆë“¤ì„ ë‚´ë³´ë‚´ê³  ì—°ê²°ë˜ì–´ ìˆëŠ” ë‰´ëŸ°ë“¤ì— í™”í•™ë¬¼ì§ˆì´ ë“¤ì–´ê°„ë‹¤. ì´ëŠ” ê° ë‰´ëŸ°ë“¤ì˜ ì „í•˜ë¥¼ ë³€ê²½í•˜ëŠ” ì—­í• ì„ í•œë‹¤. 
</figcaption>
</figure>


ê²°ê³¼ì ìœ¼ë¡œ ë‰´ëŸ°ì˜ ìƒíƒœì¸ ì „ê¸°ì  ì‹ í˜¸ëŠ” **ë¬´ì¡°ê±´ 1ê°œ**ì´ë‹¤. ê·¸ë¦¬ê³  ì´ ìƒíƒœëŠ” ì—¬ëŸ¬ ê°œì˜ `Axon Terminal`ì— ì˜í–¥ì„ ë¯¸ì¹˜ë¯€ë¡œ, ì „íŒŒëœ ì •ë³´ëŠ” ì—¬ëŸ¬ ë‰´ëŸ°ë“¤ì— ì—°ê²°ë˜ì–´ ì „íŒŒëœë‹¤. ì „ë‹¬ë°›ì€ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆì˜ ì „ê¸°ì  ìƒíƒœì— ëŒ€í•´ì„œ 3ê°€ì§€ ê°€ëŠ¥ì„±ì´ ì¡´ì¬í•œë‹¤. 
 1. **ëª¨ë‘ ì–‘ì´ì˜¨ë“¤ì´ë¼ë©´, ë‰´ëŸ°ì€ í™œì„±í™”ëœë‹¤. (+)** 
 2. **ëª¨ë‘ ìŒì´ì˜¨ë“¤ì´ë¼ë©´, ë‰´ëŸ°ì€ ë¹„í™œì„±í™”ëœë‹¤. (-)**  
 3. **ë§Œì¼ ìŒì´ì˜¨ê³¼ ì–‘ì´ì˜¨ì´ ì ì ˆí•˜ê²Œ ì„ì—¬ìˆë‹¤ë©´, í™œì„±í™”ë ìˆ˜ë„ ì•ˆë ìˆ˜ë„ ìˆë‹¤. (+ Or -)** 

ì—°ê²°ë˜ì–´ ìˆëŠ” ë‰´ëŸ°ì´ ì „ë‹¬í•˜ëŠ” ì‹ ê²½ì „ë‹¬ ë¬¼ì§ˆì˜ ìƒíƒœì— ëŒ€í•´ì„œ ë°›ëŠ” ìª½ ë‰´ëŸ°ì„ **í™œì„±í™”ì‹œí‚¤ëŠ”ì§€, ì–µì œì‹œí‚¤ëŠ”ì§€ì— ë”°ë¼ì„œ ë¬¼ì§ˆì„ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤.** ì´ëŸ¬í•œ ë‰´ëŸ°ì´ ì „ë‹¬í•˜ëŠ” ë¬¼ì§ˆì˜ êµ¬ë¶„ì€ ë”¥ëŸ¬ë‹ì˜ ë‰´ëŸ°ì„ **Excitatory** ì™€ **Inhibitory**ë¡œ êµ¬ë¶„í•œ **Thread: Circuits** <d-cite key="cammarata2020thread"/> [[post](https://distill.pub/2020/circuits/)] ì—ì„œë„ ë‚˜íƒ€ë‚˜ëŠ” ê°œë…ìœ¼ë¡œ, ë‰´ëŸ°ë“¤ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ëŠ”ë° ì•„ì£¼ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. 

> **í¥ë¶„ê³¼ ì–µì œ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ, Excitatory and Inhibitory Neurotransmitters**
* ğŸ”¥ í¥ë¶„ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ (Excitatory Neurotransmitters)
  * Na+ 
  * Acetylcholine
  * Noradrenaline 
  * Glutamate 
* â„ï¸ ì–µì œ ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ (Inhibitory Neurotransmitters)
  * Glycine
  * GABA (gamma-aminobutyric acid)
  * Cl-

<figure style="text-align:center; display:block;width:100;grid-column:middle;">
<img src="/assets/kor/neurons_as_neurons/excitation_and_inhibition.png" style="width:120%">
<figcaption>
  Excitatory Neuron ì€ ë‹¤ìŒ ë‰´ëŸ°ì„ í¥ë¶„ì‹œí‚¤ëŠ” ì—­í• ì„ í•˜ê³ , Inhibitory Neuron ì€ ë‹¤ìŒ ë‰´ëŸ°ì„ ì–µì œì‹œí‚¤ëŠ” ì—­í• ì„ í•œë‹¤. 
</figcaption>
</figure>


ì‚¬ëŒì€ ìˆ˜ë§ì€ ì¸ì§€ê³¼ì •ì„ ê±°ì¹˜ë¯€ë¡œ ì •í™•íˆ ì–´ë–¤ ë‰´ëŸ°ì´ ì–´ë–¤ ì—­í• ì„ ê°€ì§€ëŠ”ì§€, í˜„ì¬ ë‡ŒëŠ” ì–´ë–¤ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆëŠ”ì§€ ëª…í™•í•˜ì§€ ì•Šë‹¤. ë˜í•œ, ë‰´ëŸ°ë“¤ì˜ ê°’ì„ ëª¨ë‘ ì¶”ì í•˜ê¸° ìœ„í•´ì„œë„ ë§ì€ í˜„ëŒ€ê¸°ìˆ ë“¤ì´ í•„ìš”í•˜ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì™€ ë‹¤ë¥´ê²Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì€ ì…ë ¥ì— ëŒ€í•´ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë‰´ëŸ°ë“¤ì´ ì–´ë–¤ì‹ìœ¼ë¡œ ë°˜ì‘í•˜ëŠ”ì§€ ê°’ì„ ì¶”ì í•  ìˆ˜ ìˆìœ¼ë©°, ë°˜ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ ë‰´ëŸ°ë“¤ê°„ì˜ ì—°ê²°ì´ ì¡´ì¬í•œë‹¤ë©´ ì´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë””ë²„ê¹…í•  ìˆ˜ ìˆë‹¤. ë§Œì¼ ë”¥ëŸ¬ë‹ì˜ ë‰´ëŸ°ì´ ì‹ ê²½ì„¸í¬ì˜ í†µì‹ ê³¼ì •ê³¼ ë¹„ìŠ·í•˜ê²Œ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ì „ë‹¬í•œë‹¤ë©´, ë”¥ëŸ¬ë‹ì˜ ë‰´ëŸ°ì„ ë¶„ì„í•˜ëŠ” ê²ƒì´ ì‹ ê²½í•™ì˜ ë‰´ëŸ°ì„ ë¶„ì„í•˜ëŠ” ì—´ì‡ ê°€ ë  ìˆ˜ ìˆë‹¤. ê·¸ëŸ°ë°, *ë”¥ëŸ¬ë‹ì—ì„œ ë‰´ëŸ°ì´ë¼ëŠ” ê²ƒì€ ì •í™•í•˜ê²Œ ë­˜ê¹Œ?* ì´ì— ëŒ€í•œ ë‹µì„ ë‚´ë ¤ë³´ê³ ì í•œë‹¤. 

---

## Deep Learning 

ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë‚´ë¶€ì— ëŒ€í•´ì„œ ê°€ì§€ê³  ìˆëŠ” ìƒê°ì€ ëŒ€ë¶€ë¶„ ë‹¤ìŒê³¼ ê°™ì„ ê²ƒì´ë‹¤.  

> ìˆ˜ë§ì€ íŒŒë¼ë¯¸í„°ë“¤ì´ ë ˆì–´ì´ë§ˆë‹¤ ì¡´ì¬í•˜ë©°, ì…ë ¥ê³¼ ì¶œë ¥ì„ End-to-End ë¡œ ê³„ì‚°í•˜ëŠ” ë¸”ë™ë°•ìŠ¤ ëª¨ë¸ 

ëª¨ë¸ ë‚´ë¶€ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì€ ë„ˆë¬´ ì–´ë ¤ìš´ ì¼ì´ë©°, ë‚´ë¶€ì—ì„œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€, íŒŒë¼ë¯¸í„°ë“¤ì´ ì–´ë–¤ ì—­í• ì´ ìˆëŠ”ì§€ ëª…í™•í•˜ì§€ ì•Šë‹¤. 
ê·¸ëŸ¬ë‚˜ ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ì— ëŒ€í•œ ì´í•´í•œë‹¤ë©´, ëª¨ë¸ì˜ ë‚´ë¶€ë¥¼ ë‰´ëŸ°ë“¤ì˜ í†µì‹ ìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆê³  ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ëŒ€í•´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ê´€ì ì´ ìƒê¸´ë‹¤. 

> ê° ë ˆì´ì–´ë§ˆë‹¤ ë‰´ëŸ°ë“¤ì´ ë…ë¦½ì ìœ¼ë¡œ ì…ë ¥ì˜ í™œì„±í™” ì •ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ì‹ ê²½í•™ì  êµ¬ì¡° 

### Neuron & Synapse

ì‹ ê²½í•™ì  ë‰´ëŸ°ì—ì„œ í•˜ë‚˜ì˜ ë‰´ëŸ°ì€ ì—¬ëŸ¬ê°œì˜ `Dendrite` ì„ ê°€ì ¸ì„œ ì •ë³´ë¥¼ ë°›ê³ , ì¶œë ¥ìœ¼ë¡œ í•˜ë‚˜ì˜ ì „ê¸°ì  ì‹ í˜¸ê°€ ìƒê¸´ë‹¤ê³  ì„¤ëª…í•˜ì˜€ë‹¤. 
ì´ ê³¼ì •ì€ ë”¥ëŸ¬ë‹ì—ì„œ ì…ë ¥ë²¡í„°ì— ëŒ€í•´ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ë‚´ì ì„ ê³„ì‚°í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ë°©ì‹ì´ë‹¤. 

<figure style="text-align:center;">
<img src="/assets/kor/neurons_as_neurons/neuron_as_neuron.png" style="width:100%">
<figcaption>
  Figure. ì‹ ê²½í•™ì  ë‰´ëŸ°ê³¼ ë”¥ëŸ¬ë‹ ë‰´ëŸ°ì˜ ì—°ì‚°ì˜ ìœ ì‚¬ì„±. ì‹ ê²½í•™ì  ë‰´ëŸ°ì´ ì „í•˜ë¥¼ ë°”ê¾¸ëŠ” neurotransmitterë“¤ë¡œ ì¸í•´ì„œ ì¶œë ¥ì´ ìƒê¸°ëŠ” ê²ƒê³¼ ìœ ì‚¬í•˜ê²Œ, ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ë„ ì…ë ¥ë“¤ì„ ê²°í•©í•˜ì—¬ ì „í•˜ìƒíƒœë¥¼ ë‚´ë³´ë‚¸ë‹¤.
</figcaption>
</figure>


ì‹ ê²½í•™ì  ë‰´ëŸ°ì˜ ì—­í• ì´ ì‹ í˜¸ë“¤ì„ ê²°í•©í•˜ì—¬, ìƒˆë¡œìš´ ì‹ í˜¸ë¥¼ ë‚´ë³´ë‚´ëŠ” ê²ƒìœ¼ë¡œ ê³ ë ¤í•œë‹¤ë©´ ë”¥ëŸ¬ë‹ì—ì„œ `Linear Sum` ì„ í•˜ëŠ” Weightë“¤ì˜ ê²°í•©ì´ ë‰´ëŸ°ì´ë‹¤. ë”°ë¼ì„œ ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆë‹¤. 

> **ğŸš€ ì‹ ê²½í•™ì  ë‰´ëŸ°ìœ¼ë¡œë¶€í„° ë„ì¶œëœ ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ì˜ ì •ì˜** <br>
**ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°** : Weight ë“¤ì˜ ì§‘í•© (ì…ë ¥ì— ëŒ€í•´ì„œ ê²°í•©ì„ í•˜ëŠ” Weight) <br>
**ë”¥ëŸ¬ë‹ì  ì‹œëƒ…ìŠ¤** : ê°œë³„ Weight

ìœ„ì—ì„œ ì‚¬ëŒì˜ ì‹œëƒ…ìŠ¤ ê°œìˆ˜ëŠ” 600ì¡° ê°œìˆ˜ë¼ê³  í•˜ì˜€ëŠ”ë° (â­ï¸), GPT3 ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ëŠ” 1750ì–µê°œì´ë‹¤. ë”°ë¼ì„œ, GPT3 ê°€ ì‚¬ëŒë³´ë‹¤ ì‹œëƒ…ìŠ¤ì˜ ê°œìˆ˜ê°€ ë” ì ì„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ì˜ ì •ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë”¥ëŸ¬ë‹ ëª¨ë“ˆë“¤ì—ì„œ ëª‡ ê°œì˜ ë‰´ëŸ°ê³¼ ì‹œëƒ…ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ì‚´í´ë³¼ ìˆ˜ ìˆëŠ”ë°, ê°€ì¥ ê¸°ë³¸ì´ë˜ëŠ” Linear Weight ì— ëŒ€í•´ì„œ í•´ì„í•´ë³´ì<d-footnote> ë” ë³µì¡í•œ ëª¨ë“ˆë“¤ì¸ Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN) ê·¸ë¦¬ê³  GPT3 ëª¨ë¸ì˜ ë‰´ëŸ°ë“¤ì— ëŒ€í•œ ë¶„ì„ì€ [ë‰´ëŸ° - 4. ë‹¤ì¤‘ ë‰´ëŸ° ë¶„ì„] ì„ ì°¸ê³ .
</d-footnote>. ë¨¼ì €, ì‹ ê²½í•™ì  ë‰´ëŸ°ì€ `K`ê°œì˜ í™”í•™ì ì‹ í˜¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ `1`ê°œì˜ ì „ê¸°ì  ì‹ í˜¸ë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤<d-footnote> 1 ê°œì˜ ì „ê¸°ì  ì‹ í˜¸ëŠ” ë‹¤ì‹œ ê²°í•©ë˜ì–´ ìˆëŠ” ë‹¤ë¥¸ ë‰´ëŸ°ë“¤ì—ê²Œ í™”í•™ë¬¼ì§ˆì„ ì „ë‹¬í•˜ëŠ” ì—­í• ì„ í•œë‹¤. ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê´€ì ì—ì„œ ì‹ ê²½í•™ì  ë‰´ëŸ°ì€ ì—¬ëŸ¬ê°œì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê°€ì§„ë‹¤. ê·¸ë¦¬ê³  ì—¬ëŸ¬ ê°œì˜ ì¶œë ¥ì€ ë‹¤ì‹œ ì—¬ëŸ¬ ê°œì˜ ë‰´ëŸ°ë“¤ê³¼ ì—°ê²°ë˜ëŠ”ë°, ì´ ê³¼ì •ì—ì„œ ì¶œë ¥ê³¼ ë‹¤ìŒ ì…ë ¥ì€ ì„œë¡œ ë§ë¬¼ë ¤ì„œ ê²°ê³¼ë¬¼ì„ ë‚´ëŠ” ê²ƒìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤. ì´ ë•Œ, ê²°ê³¼ë¬¼ì„ ì¶œë ¥í•˜ëŠ” ìª½ì´ ì•„ë‹ˆë¼, ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” ìª½ì—ì„œ ì²˜ë¦¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ê³ ë ¤í•œë‹¤ë©´, ë‰´ëŸ°ì˜ ì¶œë ¥ì€ ë‹¨ 1ê°œë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤</d-footnote>.

* ì‹ ê²½í•™ì  ë‰´ëŸ°ì˜ ì—°ì‚°
  * (In) **ë‰´ëŸ°ì´ ë°›ì€ Kê°œì˜ ì‹ í˜¸ë“¤**: $a_1, a_2, a_3, \cdots, a_k $ (í”ŒëŸ¬ìŠ¤ ì •ë„, ë‰´ëŸ°ì´ ìŒì „í•˜ ìƒíƒœì´ë©´ 0)
  * (Weight) **ë‰´ëŸ°ì˜ Kê°œ Dendrite**: $w_1, w_2, w_3, \cdots, w_k $ (ë‚´ë³´ë‚´ëŠ” ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ ìŒ~ì–‘ì „í•˜)
  * (Out) **ì‹ ê²½ì „ë‹¬ ë¬¼ì§ˆì„ ë°›ëŠ” ë‰´ëŸ°ì˜ í™œì„±í™” ì •ë„** : $\sum_k w_k \cdot a_k$

* ë”¥ëŸ¬ë‹ì  ë‰´ëŸ°ì˜ ì—°ì‚° (`Weight` ì™€ `Activation` ë‚´ì )
  * (In) **ë‰´ëŸ° íŒŒë¼ë¯¸í„°** :  $w_1, w_2, w_3, \cdots, w_k $
  * (Weight) **ë‰´ëŸ° ì…ë ¥** : $a_1, a_2, a_3, \cdots, a_k $ 
  * (Out) **ë‰´ëŸ° ì¶œë ¥** : $\sum_k w_k \cdot a_k$

ì—¬ê¸°ì„œ ì„ í˜•ë ˆì´ì–´ê°€ ê°€ì§€ëŠ” ë‘ ê°€ì§€ Weight $W\in \mathbb{R}^{N\times K}$ê³¼ Bias $\mathbf{b}\in \mathbb{R}^{N}$ë¥¼ í•´ì„í•˜ë©´ $K$ê°œì˜ ë‰´ëŸ°ì´ ìˆìœ¼ë©°, ê° ë‰´ëŸ°ì€ $K$ ê°œì˜ ì‹ í˜¸ë¥¼ ì¢…í•©í•˜ì—¬ 1ê°œì˜ ì•„ì›ƒí’‹ì„ ë‚´ë³´ë‚¸ë‹¤. ì´ $N$ê°œì˜ ë‰´ëŸ°ë“¤ì´ ì‹ í˜¸ë¥¼ 1ê°œì”© ë‚´ë³´ë‚´ë¯€ë¡œ, ê²°ê³¼ì ìœ¼ë¡œ $N$ ì°¨ì›ì˜ ì¶œë ¥ì´ë‹¤. 

$$
\begin{gather}
\mathbf{y} = W\mathbf{x} + \mathbf{b}  \\
\begin{bmatrix}
  y_1 \\ 
  y_2 \\
  \vdots \\ 
  y_N
\end{bmatrix}
=
\begin{bmatrix}
  w_{11} & w_{12}& \cdots & w_{1K} \\ 
  w_{21} & w_{22}& \cdots & w_{2K} \\ 
  \vdots \\ 
  w_{N1} & w_{N2}& \cdots & w_{NK} \\ 
\end{bmatrix}
\cdot 
\begin{bmatrix}
  x_1 \\ 
  x_2 \\
  \vdots \\ 
  x_K
\end{bmatrix}
+ 
\begin{bmatrix}
  b_1 \\ 
  b_2 \\
  \vdots \\ 
  b_N
\end{bmatrix}
\end{gather}
$$

* â­ï¸ ë‰´ëŸ°ì˜ ê°œìˆ˜ : $N$ (Dimension of Output)
* â­ï¸ ì‹œëƒ…ìŠ¤ì˜ ê°œìˆ˜ : $N\times K$ (Number of Weights)

ê²°êµ­ ë”¥ëŸ¬ë‹ì˜ ë‰´ëŸ°ì€ ì…ë ¥ì„ í•´ì„í•´ì„œ ì•„ì›ƒí’‹ì„ ë‚´ë³´ë‚´ëŠ” weight ì— ëŒ€í•œ group ìœ¼ë¡œ ì •ì˜ê°€ ëœë‹¤. ë”¥ëŸ¬ë‹ì—ëŠ” Linearê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ ëª¨ë“ˆë“¤ì´ ì¡´ì¬í•˜ë©° ì´ì— ëŒ€í•œ í•´ì„ë„ Linearë¥¼ í•´ì„í•œ ê²ƒì²˜ëŸ¼ ê°€ëŠ¥í•˜ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê¸€ì˜ ëª©ì ì€ ë”¥ëŸ¬ë‹ê³¼ ì‹ ê²½í•™ì ì¸ ë‰´ëŸ°ì„ ë¹„êµí•˜ëŠ” ê²ƒì´ë¯€ë¡œ í•´ë‹¹ ì„ í˜• ë‰´ëŸ°ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ê²½í•™ì ì¸ íŠ¹ì§•ì„ ë¹„êµí•´ë³´ì. 


## Comparison 


### Forward 


### Backward

## Type of Information

The most significant unfairness of deep learning compared to humans is the difference in input. Human  eyes receive information as input every moment, and about 200 images are received in high resolution per second. But the deep learning models take an input of the level of an image.
Therefore the recent models are designed to take more inputs in order to approximate the amount of information a human receives. However, deep learning still has the disadvantage of reacting only when input is given.
â†’ What can deep learning do if there is no input?


### Absence of State

In humans, neurons can respond and process information without being given input. 
(e.g., you can recall a picture in your mind and draw conclusions or create new ideas from that picture)
This process is considered to retrieve information which is stored in the brain's long-term memory, but the deep learning parameters are configured to perform operations on given inputs and there is no memory.


### State of Creature

Another difference is the type of input. While humans receive information through sensory organs, deep learning models have a fixed input space, and visual, linguistic, or audio information comes in through the input layer. Therefore, the information processed by deep learning is only the input and the output calculated by the internal neurons. However, for humans, there is additional information in addition to the information received as input. It is the state of the body or cognition.


### State of body

> Do deep learning models change calculation results just because they are tired? No.


In humans, even given the same input, the result can be changed by current hormonal conditions. For example, If you feel sad, you can have different interpretations of the same picture. This suggests that the processing of neurons can be different depending on the body's states.


### State of cognition

> Does deep learning keep thinking about information it has seen before? No.

Cognitive contrast is a principle in which the next information is distorted and interpreted by the previously seen information. For example, a tiger next to an elephant is perceived as small because the elephant is large.
However we cannot be sure that deep learning neurons analyze things based on this principle of cognitive contrast. They are more likely to interpret simply depending on the information currently available.

## Conclusion 
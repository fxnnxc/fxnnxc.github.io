<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | 1.3 Interpret Neurons with Neurons</title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="üìô Chapter 1. Neuron <br> <em> Can you find meaningful neurons with neurons?</em>" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/holders/3_interpretneurons_with_neurons/">
    
    <!-- Dark Mode -->
    

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "1.3 Interpret Neurons with Neurons",
      "description": "üìô Chapter 1. Neuron <br> <em> Can you find meaningful neurons with neurons?</em>",
      "published": "August 22, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Youngju Joung",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Enver Menadjiev",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="https://fxnnxc.github.io/" style="margin-left:20px ;">
              <!--Bumjini-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">Bumjini    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->
              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_papers/"> Papers</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_articles/"> Articles</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_projects/"> Projects</a>
              </li>

              <!-- Other pages -->
              <li style="font-size: 17px" class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Others</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/side_papers/">üóÇÔ∏è side-paper</a>
                  <a class="dropdown-item" href="/side_articles/">ü•ï side-articles</a>
                  <a class="dropdown-item" href="/book/">üìö book (korean)</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">1.3 Interpret Neurons with Neurons</h1>
        <p>üìô Chapter 1. Neuron <br> <em> Can you find meaningful neurons with neurons?</em></p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="interpret-neurons-with-neurons">Interpret Neurons with Neurons</h2>

<p>Inside of a deep neural network, numerous neurons exist, and each of them activated by some specific patterns. We can easily assume the existence of such neurons in the complex inside, but finding such neurons requires expensive efforts such as Network Dissection and  CLIP Dissection. Unlike visualizing the detected region of a neuron, a much easier way is learning a classifier to verify the semantic meaning of neurons so that the weight of the classifier reveals the relationship between the activation of the neuron and a specific pattern. 
To further understand the easiness of such a method, assume the situation where we want to find a neuron detecting ‚ÄúThe Stripe Pattern in Zebra‚Äù.</p>

<ul>
  <li>
<strong>Difficulty 1</strong>: there are numerous neurons in a network which are fired with a zebra image. <br> (Multiple neurons are activated by a single image)</li>
  <li>
<strong>Difficulty 2</strong>: we don‚Äôt know how much to be activated for the pattern.  <br> (The proper threshold for activation)</li>
  <li>
<strong>Difficulty 3</strong>:  The proportion of activation might not be 100%. In what threshold, can we Difficulty that the neuron has the semantic pattern? <br> (How much <code class="language-plaintext highlighter-rouge"># Activated Samples</code> / <code class="language-plaintext highlighter-rouge"># Total Samples?</code> )</li>
</ul>

<p>These difficulties has the same goal:</p>
<blockquote style="background-color:#DDFFFF">
  <p>How can we determine the features of a neuron with activation patterns?</p>
</blockquote>

<p>To solve this problem with another deep neural network, we must consider two types of neurons, a neuron capturing a semantic pattern and a neuron interpreting the activation of the neuron. Two neurons have the following domain and co-domain.</p>
<ul>
  <li>Pattern neuron : Input ‚Üí Activation Score ($x \mapsto h$)</li>
  <li>Interpretation neuron :  Activation Score ‚Üí Concept ($h \mapsto C$)</li>
</ul>

<h2 id="pattern-neuron">Pattern Neuron</h2>

<p>A pattern neuron has positively correlated activation patterns with respect to a specific semantic image, such as strip patterns. As the intensity of the activation is stronger, the activation of the neuron is higher. On the other hand, if the pattern does not exist in the input, the neuron must not propagate signals.  In addition, this assumption could be stochastic as the activation patterns could have noise.</p>

<figure style="text-align:left; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/feature_neuron.png" style="width:100%">
<figcaption>
    <p>Figure. Several inputs are mapped to the neuron‚Äôs output. They leave activation signals.  With the assumption that the neuron has semantic meaning, large value of <code class="language-plaintext highlighter-rouge">F</code> will be considered to have more degree of a feature.</p>
  </figcaption>
</figure>

<p>The mathematical formulation of pattern neuron is as follows:</p>

<blockquote style="background-color:#FFEFEF; font-style:normal;">
  <p><strong>Formulation for a pattern neuron \(h = f_n(x)\)</strong></p>
  <ul>
    <li>$x$ : an input</li>
    <li>$h$ : activation of the neuron</li>
    <li>$f_n$ : a function maps input $x$ to activation $h$.</li>
    <li>$c_n$ : the concept related to neuron $n$</li>
  </ul>
</blockquote>

<h2 id="interpretation-neurons">Interpretation Neurons</h2>

<p>The interpretation neuron takes activation score as an input and outputs the decision of concept with a separate neuron. Note that the interpretation neuron is not internal neurons of the original network. They are separate neurons which will be trained for the interpretation of activation values.</p>

<figure style="text-align:left; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/interpretation_neuron.png" style="width:100%">
<figcaption>
Figure. Several inputs are mapped to the neuron and leave activations. The interpretation neuron will be trained to classify the concept patterns with the activation signals. 
</figcaption>
</figure>

<p>The interpretation neuron is a function $g$ which can have the most simplest form as follows:</p>

\[g_n = \sigma (wh+b)\]

<p>Here $\sigma$ is a sigmoid function to be used for the decision of a concept. With such formulation we can interpret the decision as follows:
If there is positive correlation between $h$ and concept $c$, the weight will be positive 
If there is no correlation between the activation and concept, the weight will be close to zero.</p>

<blockquote style="background-color:#FFEFEF; font-style:normal;">
  <p><strong>Formulation of an interpretation neuron: \(c = g(h)\)</strong></p>
  <ul>
    <li>$h$ : an input</li>
    <li>$c$ : the concept to be verified for an input</li>
    <li>$g$ : a mapping from $h$ to $c$.</li>
    <li>$w,b$ : weight and bias for the classifier $g$.</li>
  </ul>
</blockquote>

<p>This classifier can help us to mitigate the difficulties 2 and 3 (The proper threshold for activation, and How much # Activated Samples / # Total Samples?). However, difficulty 1 (numerous neurons) is not solved with learning a classifier with input size 1. To solve it, we further formulate a classifier with high-dimensional input space.</p>

<h2 id="interpretation-neuron-for-multiple-neurons">Interpretation Neuron for Multiple Neurons</h2>

<p>There is not much difference between 1D input space and high-dimensional input space. We just widen the input space. However, this simple trick will ease the interpretation of a neuron and the combination of several neurons.</p>

<blockquote style="background-color:#FFEFEF; font-style:normal;">
  <p><strong>Formulation for an interpretation neuron: \(c=g(\mathbf{h})\)</strong></p>
  <ul>
    <li>$\mathbf{h}$ : an input of size $D$-dimension</li>
    <li>$c$ : the concept to be verified for an input</li>
    <li>$g$ : a mapping from $h$ to $c$.</li>
    <li>$W, \mathbf{b}$ : weight and bias for the classifier $g$.</li>
  </ul>
</blockquote>

<p>Most previous work uses the representation of a layer for an input. The verification of a concept is done by learning a classifier whose input is a layer-representation and the output is a boolean for a specific concept. Note that when we can actually learn this, we may say there is a concept in activations. Even though this formulation has probed neurons with layer-representation, we don‚Äôt have to limit the function. We can learn a classifier whose input is the whole activation of a network. In this case, we can verify the neurons at once!</p>

<h2 id="probing-">Probing üß™</h2>

<p>The verification of neurons is called <em>probing</em>. We probe the semantic information of  neurons. The overall algorithm is as follows:</p>

<p><strong>Step1</strong>: Prepare samples</p>
<ul>
  <li>
<span style="color:green"> Positive </span>  : Inputs which have concepts in its input space.  (Label 1)</li>
  <li>
<span style="color:red"> Negative </span> : random or opposite conceptual images. (Label 0)</li>
</ul>

<p><strong>Step2</strong>: Gather all activations of a network with samples in Step 1.</p>

<p><strong>Step3</strong>: Replace inputs in Step1 with the activations in Step2</p>

<p><strong>Step4</strong>: Train a classifier whose input is the activation score and the concept labels.</p>

<p><strong>Step5</strong>: Check the accuracy to see the pruning results.</p>

<p><strong>Step6</strong>: Check the weight to verify the important neurons.</p>

<h3 id="linear-probing">Linear Probing</h3>

<p>If you use a linear classifier in probing, it is called linear probing. 
The advantage of linear probing is the ease of weight interpretation.  As we want to verify the semantic information of neurons, we must know the relation between each neuron and the concept. The weight can provide this information</p>

<h3 id="non-linear-probing">Non-linear Probing</h3>

<p>If you use a non-linear classifier in probing, it is called linear probing. 
 The advantage of non-linear probing is that the concept could be complex and the linear relationship between neurons and concepts may not be enough, but the non-linear relationship may be.</p>

<h2 id="interpret-chess-concepts-">Interpret Chess Concepts ‚ôú</h2>

<p>Chess has many meaningful concepts in board states such as ‚ÄúCheckmate‚Äù and ‚ÄúMobility‚Äú. 
Thomas et al. <d-cite key="mcgrath2022acquisition"></d-cite> investigate the concepts in chess with AlphaZero model.
Note that the network obtains only a board state and outputs preferred action and there is no explicit encoding of concepts. Therefore, the verification of neurons is about the existence of meaningful chess concepts in the internal representations.</p>

<figure style="text-align:center; display:block;width:100;">
<div style="display: flex; justify-content: center">
<img src="/assets/img/neurons_interpret_neurons/Interpret%20Chess%20Concepts.png" style="width:60%">
</div>
<figcaption>
Figure. Probing for human-encoded chess concepts in the AlphaZero network: generalize linear function $g(z^d)$ is trained to approximate $c(z^0)$.
</figcaption>
</figure>

<h4>What-When-Where plot for probing concepts.</h4>
<figure style="text-align:center; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/chess_concept_king.png" style="width:100%">
<figcaption>
Figure. <strong>What-when-where</strong> (Checkmate-Training Step-Layer) plot to visualize the emergence of concepts in the network. Note that the z-axis is the accuracy of the probing network. As the training goes on, the concept of checkmate emerges. 
</figcaption>
</figure>
<figure style="text-align:center; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/chess_concept_queen.png" style="width:100%">
<figcaption>
Figure. <strong>What-when-where</strong> (Queen-Training Step-Layer) plot to visualize the emergence of concepts in the network. As training goes on, the concept "Can capture queen" emerges. The emerged layers are deeper compared to the checkmate concept. 
</figcaption>
</figure>

<p>The above accuracy is for binary classification. We can train a regression model to probe concepts. The Figures below show the probed continuous values while training. Note that as training goes on, the probed continuous values increased similar to the binary classification results.</p>

<figure style="text-align:center; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/regression.png" style="width:100%">
<figcaption>
Figure. Regression probing. 
</figcaption>
</figure>

<h2 id="testing-with-concept-activation-vector-">Testing with Concept Activation Vector ü¶ì</h2>

<p>The natural question followed by the concept is the usefulness of concepts.<br>
That is, how important the concept stripe is for the class zebra. 
Similarly, how much is the concept of red important for the class firefighter? 
To answer this question, we need a qualitative measure with concepts and classification logits. 
Testing with Concept Activation Vector (TCAV) <d-cite key="kim2018interpretability"></d-cite> is a measure that counts the number of samples that increased the class logic as the activation intervened with concept direction.</p>

<p>Assume that we obtained the directional vector $v$  for the concept $C$ with probing. That is, $v_C^l$ is a weight in the probing classifier for concept $C$ and layer $l$. 
As we increase the activation pattern with the direction, we get more likelihood of concept $C$. 
That is, we can intervene the representation $f_l(x)$ in the direction of $v_C^l$,
$f_l(x) + \epsilon v_C^l$. TCAV utilizes the intervention to check whether it increases the classification logit.
This is a natural way of increasing concept. For example, the increased concept of stripe pattern will increase the logit of the zebra class. 
TCAV is a quantitative measure to this question and answers it with the ratio of samples which increases the logic.</p>

<p>In summary: the classification logit will be increased if the amount of a concept increases.</p>

<h3 id="conceptual-sensitivity-of-class-k-to-concept-c">Conceptual Sensitivity of class k to concept C</h3>

<p>To quantitatively score the increased logit, the authors proposed Conceptual Sensitivity (CS) as follows:</p>

\[\begin{aligned}
S_{C,k,l}(\mathbf{x}) 
&amp;= \lim_{\epsilon \rightarrow 0} \frac{h_{l,k}(f_l (\mathbf{x}) + \epsilon v_C^l) - h_{l,k}(f_l(\mathbf{x}))}{\epsilon} \\
&amp;= \nabla h_{l,k}(f_l(\mathbf{x})) \cdot v_C^{l}
\end{aligned}\]

<p>where $h_{l,k}$ is the logit of class $k$ and $\mathbf{x}$ is input. Note that CS computes the alignment between the directional vector and the concept activation vector.</p>

<h3 id="tcav">TCAV</h3>

<p>With CS score, the authors compute the validity of CS score over enough number of samples.</p>

\[\mathrm{TCAV}_{Q_{C, k,l}} = \frac{\vert \{ x\in X_k : S_{C,k,l} (x) &gt; 0  \}\vert }{\vert X_k \vert}\]

<p>where $X_k$ is the collection of samples with label $k$ such as collection of zebra images. Interpretation of TCAV results can be done as follows:</p>

<ul>
  <li>üìå If the concept has nothing to do with the class, the score will be low</li>
  <li>üìå If the TCAV score has too high variance, we can not believe it <br>(requires additional statistical tests)</li>
  <li>üìå <strong>If the TCAV score is high with low variance, <br> we can say the concept increases the class logit.</strong>
</li>
</ul>

<figure style="text-align:center; display:block;width:100;">
<img src="/assets/img/neurons_interpret_neurons/tcav.png" style="width:100%">
<figcaption>
Figure. TCAV. results for two classes and three concepts respectively. (*) indicates the failure cases for the statistical test. Note that: <br>
<strong>(1)</strong> Red has a higher TCAV score than other concepts in the fire engine class. <br>
<strong>(2)</strong> Only specific modules encode stripe patterns for the zebra class.  <br> ¬© Copyright: TCAV paper 
</figcaption>
</figure>

<h2 id="conclusion">Conclusion</h2>

<p>In this section, we study a way to interpret neurons (conceptual representation) with other neurons (probing classifier). The probing technique is widely used to verify the semantic information in neural networks. Recently, Kenneth<d-cite key="li2022emergent"></d-cite> applied both linear and non-linear probings to verify the existence of conceptual board state in GPT. We believe more techniques utilizing neurons to interpret neurons in trained neural networks will be developed.</p>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--
    </div>
 -->
      <hr>
<div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;">
    <script>
      let giscusTheme = localStorage.getItem("theme");
      let giscusAttributes = {
          "src": "https://giscus.app/client.js",
          "data-repo": "fxnnxc/fxnnxc",
          "data-repo-id": "MDEwOlJlcG9zaXRvcnkzMjQ2NjUxMTU=",
          "data-category": "Q&A",
          "data-category-id": "DIC_kwDOE1n_G84CYOk_",
          "data-mapping": "title",
          "data-strict": "0",
          "data-reactions-enabled": "1",
          "data-emit-metadata": "0",
          "data-input-position": "top",
          "data-theme": giscusTheme,
          "data-lang": "en",
          "crossorigin": "anonymous",
          "async": "",
      };
  
  
      let giscusScript = document.createElement("script");
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById("giscus_thread").appendChild(giscusScript);
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by giscus.</a>
</noscript>
  </div>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  <center>
    <a  href="">
    <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </a>
  </center>
  <hr> 

  </html>

<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | 2.1 Introduction to Transformer</title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="üìï Chapter 2. GPT <br> <em>Computational Interpretation of Circuits</em> " />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/holders/5_transformer_introduction/">
    
    <!-- Dark Mode -->
    

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "2.1 Introduction to Transformer",
      "description": "üìï Chapter 2. GPT <br> <em>Computational Interpretation of Circuits</em> ",
      "published": "September 8, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Youngju Joung",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Enver Menadjiev",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="https://fxnnxc.github.io/" style="margin-left:20px ;">
              <!--Bumjini-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">Bumjini    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->
              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_papers/"> Papers</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_articles/"> Articles</a>
              </li>

              <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/main_projects/"> Projects</a>
              </li>

              <!-- Other pages -->
              <li style="font-size: 17px" class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Others</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/side_papers/">üóÇÔ∏è side-paper</a>
                  <a class="dropdown-item" href="/side_articles/">ü•ï side-articles</a>
                  <a class="dropdown-item" href="/book/">üìö book (korean)</a>
                </div>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">2.1 Introduction to Transformer</h1>
        <p>üìï Chapter 2. GPT <br> <em>Computational Interpretation of Circuits</em> </p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="introduction">Introduction</h2>

<p>Interpretation of GPT is the most import task in deep learning to provide not only advanced but also reliable deep neural network. 
This article is about the interpretation of representations in GPT (transformer decoder-only model). 
Most of ideas in this post comes from <a href="https://transformer-circuits.pub/2021/framework/index.html" target="_blank" rel="noopener noreferrer">A Mathematical Framework for Transformer Circuits</a>, and we add some new thoughts to interpret the GPT.</p>

<p>The topics described in this article are as follows:</p>

<ul>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#FFDDDD;padding:2px;"> 1. Streams </span> : the stream of token representations over layers</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#DDFFDD;padding:2px;"> 2. Residual Spaces </span> : communication between connected spaces.</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#DDDDFF;padding:2px;"> 3. Read and Write </span> : interpret residual stream as read and write modules</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#FFFFDD;padding:2px;"> 4. Logit Lens </span> : getting contribution of each block</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#FFDDFF;padding:2px;"> 5. Token Communication </span> : information passing in tokens.</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#DDFFFF;padding:2px;"> 6. GPT Modules </span> : description of basic modules in GPT : block, MLP, ATTN</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#DDDDDD;padding:2px;"> 7. Implementation </span> : verify the forward passes of modules</li>
  <li>
<span style="font-weight:400;border:1px solid #FFDDDD;border-radius:10px;background-color:#FFDEAD;padding:2px;"> 8. Interpretability </span> : find out where knowledge is stored</li>
</ul>

<h3 id="gpt--causal-language-modeling">GPT : Causal Language Modeling</h3>

<p>GPT is an autoregressive token generator.</p>

<figure>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211230&amp;authkey=%21AO9pKX8DtFdJnWU&amp;width=1821&amp;height=863">
</figure>

<h3 id="simplest--embed-and-unembed">Simplest : Embed and Unembed</h3>

<p>The most simplest form of token generation is done by embedding the current token and unembed the next token.</p>

<figure>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211229&amp;authkey=%21AK8ktMXEvRsUbe8&amp;width=1736&amp;height=642">
</figure>

<!-- 
---

## 1. Streams 

<!-- Slideshow container -->
<div style="display:flex;justify-content:center; overflow: show;">
<div class="slideshow-container" style="margin-left:0rem;">
  <!-- Full-width images with number and caption text -->
  <div class="mySlides">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4rem;">
    <strong> [1/3]</strong> Transformer  Architecture Overview
    </figcaption>
    <img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211228&amp;authkey=%21AFMCx1hgl4GVDtk&amp;width=688&amp;height=625" style="width:40rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
    
  </div>

  <div class="mySlides">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4rem;">
    <strong> [2/3]</strong> Multi Layer Perceptron Architecture Overview
    </figcaption>
    <img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211227&amp;authkey=%21ACTgYM18WFSPVJc&amp;width=508&amp;height=416" style="width:40rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
  </div>

  <div class="mySlides">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4rem;">
    <strong> [3/3]</strong> Multi Head Attention Architecture Overview
    </figcaption>
    <img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211226&amp;authkey=%21ALIez9lD-dcrIG4&amp;width=684&amp;height=351" style="width:40rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
  </div>

  <!-- Next and previous buttons -->
  <a class="prev" onclick="plusSlides(-1)">‚ùÆ</a>
  <a class="next" onclick="plusSlides(1)">‚ùØ</a>
    <br>
    <!-- The dots/circles -->
    <div style="text-align:center">
    <span class="dot" onclick="currentSlide(1)"></span>
    <span class="dot" onclick="currentSlide(2)"></span>
    <span class="dot" onclick="currentSlide(3)"></span>
    </div>
</div>
</div>

<p>‚Äî ‚Äì&gt;</p>

<h2 id="2-residual-spaces">2. Residual Spaces</h2>

<figure>
<figcaption>
    <p>Figure.  Residual space image is obtained from <a href="https://transformer-circuits.pub/2021/framework/index.html" target="_blank" rel="noopener noreferrer">A Mathematical Framework</a>.</p>
  </figcaption>
<img src="https://drive.google.com/uc?export=view&amp;id=1UQos94yTCB0JeYy1GExR0xhgKMhJa1c6">

</figure>

<hr>

<h2 id="3-read-and-write">3. Read and Write</h2>

<p>The input representation $x$ is encoded by a module $E_i:x\rightarrow r_i(x)$ and further added with the identity representation. 
The hidden representations $h_i$ where $i$ is the location of representation are as follows:</p>

\[\begin{gather}
h_0 = x \\
h_1 = x + r_1(x)  \\ 
\Rightarrow h_2 = x + r_1(x) +  r2(x + r_1(x))
\end{gather}\]

<center>
<figure>
<figcaption style="text-align:center;color:#8888FF;">
Figure. 
</figcaption>
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211224&amp;authkey=%21ALYx4PD6PtalR30&amp;width=510&amp;height=455" style="width:auto;height:30rem;border:2px #DDDDFF solid;">
</figure>
</center>

<hr>

<h2 id="4-logit-lens">4. Logit Lens</h2>

<p>As all the representations are linearly added, we can decompose the contribution of each block or location. 
By combining the idea that the final hidden representation is further mapped to the vocabulary, we can factorize the logits of vocabulary as follows.</p>

<div style="display:flex;justify-content:center; overflow: show;">
<figure style="width:70rem;">
<img src="https://onedrive.live.com/embed?resid=AE042A624064F8CA%211225&amp;authkey=%21AGaBzLs1C31PeNA&amp;width=952&amp;height=613">
<figcaption style="text-align:center;color:#8888FF;">
Figure. 
</figcaption>
</figure>
</div>

<hr>

<h2 id="5-gpt-modules">5. GPT Modules</h2>

<!-- Slideshow container -->
<div style="display:flex;justify-content:center; overflow: show;">
<div class="slideshow-container" style="width:100rem;">
  <!-- Full-width images with number and caption text -->
  <div class="mySlides2">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4em;">
    <strong> [1/3]</strong> Transformer  Architecture Overview
    </figcaption>
    <img src="https://drive.google.com/uc?export=view&amp;id=1fSy0KqpOuG7PRGkCi8PQStuaoD2bzTa0" style="width:60rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
    
  </div>

  <div class="mySlides2">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4rem;">
    <strong> [2/3]</strong> Multi Layer Perceptron Architecture Overview
    </figcaption>
    <img src="https://drive.google.com/uc?export=view&amp;id=19Ty1Re3adPRGtJeVlyv12e0IXtpmm6r-" style="width:60rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
  </div>

  <div class="mySlides2">
    <figcaption style="text-align:center;color:AAAAFF;font-size:1.4rem;">
    <strong> [3/3]</strong> Multi Head Attention Architecture Overview
    </figcaption>
    <img src="https://drive.google.com/uc?export=view&amp;id=1R0K5MlHI4kmFqvfwVpK45w4243GyEotX" style="width:60rem;padding-right:5rem;padding-left:5rem;border:2px #DDDDFF solid;">
  </div>

  <!-- Next and previous buttons -->
  <a class="prev" onclick="AplusSlides(-1)">‚ùÆ</a>
  <a class="next" onclick="AplusSlides(1)">‚ùØ</a>

<br>
<!-- The dots/circles -->
<div style="text-align:center">
  <span class="dot2" onclick="AcurrentSlide(1)"></span>
  <span class="dot2" onclick="AcurrentSlide(2)"></span>
  <span class="dot2" onclick="AcurrentSlide(3)"></span>
</div>
</div>
</div>

<hr>

<h2 id="6-token-communication">6. Token Communication</h2>

<p>The residual stream only combines representations of modules in a specific token stream. In other words, there is no communication between tokens if we don‚Äôt mix the representations. 
A way to mix representations in the transformer is the multi-head attention (MHA) pass information in each token weighted by attention scores.</p>

<ul>
  <li>All the tokens will ask other tokens ‚Äúhow much information to give to the query‚Äù</li>
  <li>Each token will give value weighted by attention score (query * key)</li>
</ul>

<p>Note that the stream of the query token will be replaced by values of other tokens unless query get higher attention to itself. 
For example, if the values of other tokens are noise, the attention score of itself should be high to mitigate the disturbance of noise.</p>

<figure>
<img src="https://drive.google.com/uc?export=view&amp;id=1ZqmEhrTnagm67jVur-zeBAhZxekMnxJA">
<figcaption>
    <p>Figure. Residual space image is obtained from <a href="https://transformer-circuits.pub/2021/framework/index.html" target="_blank" rel="noopener noreferrer">A Mathematical Framework </a>.</p>
  </figcaption>
</figure>

<h3 id="multimodal-token-communication">Multimodal Token Communication</h3>

<p>The token communication is essential in <strong>text-to-image</strong> generation such as Parti <a href="https://sites.research.google/parti/" target="_blank" rel="noopener noreferrer">Parti Google</a>
<strong>In multimodality, the values will be text representation which are injected to the stream of image representations.</strong></p>

<p><img src="https://sites.research.google/parti/assets/parti_overview.jpg" style="width:100%"></p>

<hr>

<h2 id="7-implementations">7. Implementations</h2>

<figure style="">
<figcaption style="text-align:left;color:#8888FF;">
üë©üèª‚Äçüíª Please click the image to see details of GPT block forwarding.
</figcaption>
<img src="https://drive.google.com/uc?export=view&amp;id=1xCTc2ovedTFFy3luGHz8Ixik5peNJlMM" onclick="window.open(this.src)" role="button">
</figure>

<figure style="">
<figcaption style="text-align:left;color:#8888FF;">
üë®üèª‚Äçüíª Please click the image to see details of multi head attention forwarding.
</figcaption>
<img src="https://drive.google.com/uc?export=view&amp;id=1BA5QR8cRtOdP8bcyn2RJEEdsI1MmVS_M" onclick="window.open(this.src)" role="button">
</figure>

<hr>

<h2 id="8-interpretability">8. Interpretability</h2>

<p>How do the Transformer-based models perform well? How do they store the knowledge? We need to find out how they work, and there are some methods to make interpretations of predictions.</p>

<h3 id="knowledge-attribution">Knowledge Attribution</h3>

<figure>
<img alt="knowledge attribution" src="https://github.com/team-sail/team-sail.github.io/assets/63037270/9d223908-0f6f-4825-9a2a-d14616944451">
<figcaption>
    <p>Figure. Knowledge Neurons in Pretrained Transformers <a href="https://arxiv.org/pdf/2104.08696.pdf" target="_blank" rel="noopener noreferrer">Dai et al., 2022</a>.</p>
  </figcaption>
</figure>

<p>The feed-forward module is regarded as a key-value memory.</p>

\[FFN(x) = f(x \cdot K^{\top})\cdot V \quad where\; K, V \in \mathbb{R}^{d_m \times d}\]

<p>In this context, we can try finding out which neurons in the FFN have knowledge of a specific prediction. The <strong>Knowledge Attribution</strong> method allows measuring the contribution of each neuron to prediction when performing a fill-in-the-blank cloze task. The attribution score of each neuron is defined as follows. $w_i^{(l)}$ denotes the $i$-th intermediate neuron in the $l$-th FFN.</p>

\[Attr(w_i^{(l)}) = \bar{w}_i^{(l)} \int_{\alpha = 0}^{1} \frac{\partial P_x(\alpha \bar{w}_i^{(l)})}{\partial w_i^{(l)}}d\alpha\]

<p>Intuitively, as $\alpha$ changes from $0$ to $1$, by integrating the gradients, $Attr(w_i^{(l)})$ accumulates the output probability change caused by the change of $w_i^{(l)}$.</p>

<!-- 

### Patching

<figure>
<img width="507" alt="Path-patching" src="https://github.com/team-sail/team-sail.github.io/assets/63037270/70bcd384-05af-47ca-963a-4495c74c7283">
<figcaption markdown="1">
Figure. Patching [Wang et al., 2023](https://iclr.cc/media/PosterPDFs/ICLR%202023/11341.png?t=1682885776.8460147). 
</figcaption>
</figure>

**Patching** refers to replacing activations from a different input to identify which component causes an effect on the prediction.

<figure>
<img alt="patching" src="https://github.com/team-sail/team-sail.github.io/assets/63037270/2e30109e-4295-4043-aee8-87da4b66b9be">
<figcaption markdown="1">
Figure. Causal Traces [Meng et al., 2022](https://arxiv.org/abs/2202.05262). 
</figcaption>
</figure>

We can measure the influence of the target node by changing its (noised) activation to a clean value.

<figure>
<img alt="results" src="https://github.com/team-sail/team-sail.github.io/assets/63037270/8279343e-549e-445e-b111-b1e95d9ffa7d">
<figcaption markdown="1">
Figure. Results [Meng et al., 2022](https://arxiv.org/abs/2202.05262). 
</figcaption>
</figure>

To analyze the results, the AIE score is used as a metric. It can be computed by $Avg(P_{replaced}[o] - P_{corrupted}[o])$ where $o$ denotes the correct output. As we can see in the figure, the last token of the subject has a significant impact on the causal relationship in the early site layer. In addition, the MLP of the early site and the attention mechanism of the late site appear to play an important role in calculating the final prediction.

<script src="/assets/js/curriculum_2_1.js"> -->

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--
    </div>
 -->
      <hr>
<div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;">
    <script>
      let giscusTheme = localStorage.getItem("theme");
      let giscusAttributes = {
          "src": "https://giscus.app/client.js",
          "data-repo": "fxnnxc/fxnnxc",
          "data-repo-id": "MDEwOlJlcG9zaXRvcnkzMjQ2NjUxMTU=",
          "data-category": "Q&A",
          "data-category-id": "DIC_kwDOE1n_G84CYOk_",
          "data-mapping": "title",
          "data-strict": "0",
          "data-reactions-enabled": "1",
          "data-emit-metadata": "0",
          "data-input-position": "top",
          "data-theme": giscusTheme,
          "data-lang": "en",
          "crossorigin": "anonymous",
          "async": "",
      };
  
  
      let giscusScript = document.createElement("script");
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById("giscus_thread").appendChild(giscusScript);
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by giscus.</a>
</noscript>
  </div>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  <center>
    <a  href="">
    <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </a>
  </center>
  <hr> 

  </html>

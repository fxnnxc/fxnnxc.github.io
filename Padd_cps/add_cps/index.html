<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bumjini | ADD-CPS (Cyber Physical System)</title>
    <meta name="author" content="Bumjini  " />
    <meta name="description" content="Project" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü™¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://fxnnxc.github.io/Padd_cps/add_cps/">
    
    <!-- Dark Mode -->
    


    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "ADD-CPS (Cyber Physical System)",
      "description": "Project",
      "published": "July 1, 2022",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="sticky-bottom-footer">

    <!-- Header -->    
    <center>
      <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </center>
    <hr> 

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">ADD-CPS (Cyber Physical System)</h1>
        <p>Project</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="Ïó∞Íµ¨-Í∞úÏöî">Ïó∞Íµ¨ Í∞úÏöî</h2>

<p>Ìï¥Îãπ Ïó∞Íµ¨Îäî Î≥¥ÏôÑÎêú Ïó∞Íµ¨Î°ú Ìï¥Îãπ Î≥¥Í≥†ÏÑúÏóêÎäî Í≥µÍ∞ú Í∞ÄÎä•Ìïú Î∂ÄÎ∂ÑÎßå Ï†ïÎ¶¨ÌïòÏòÄÎã§.</p>

<h2 id="Ïó∞Íµ¨-ÏùºÏ†ï">Ïó∞Íµ¨ ÏùºÏ†ï</h2>

<ul class="timeline">
<strong style="font-size:20px"> 2021</strong> 
<li>
<span class="badge-toc">10. Patent &amp; Software</span> MultiRobot-Allocation Simulator</li> 
<li>
<span class="badge-toc">10. Paper</span> Generating Multi-agent Patrol Areas by Reinforcement Learning </li>
<li>
<span class="badge-toc">11. Paper</span> Analyzing Conflicting Objectives in Deep Reinforcement Learning... </li>
<li>
<span class="badge-toc">12. SCI Paper</span> Scheduling PID Attitude and Position Control Frequencies...</li>
<li>
<span class="badge-toc">12. SCI Paper</span> Cooperative Multi-Robot Task Allocation with Reinforcement Learning </li>
<li>
<span class="badge-toc">12. Evaluation </span> First Year Final</li>
</ul>
<ul class="timeline">
<strong style="font-size:20px"> 2022</strong> 
<li>
<span class="badge-toc">06. Paper</span> Automatic Analysis of Mobile Robot Decision Process...</li>

</ul>

<ul class="timeline">
<strong style="font-size:20px"> 2023</strong> 
<li>
<span class="badge-toc">02. Paper </span> Sample Filtering for Efficient Online Distillation...</li>
<li><span class="badge-toc">07. Software : CPS Core </span></li>
<li>
<span class="badge-toc">08. Paper: </span> TBD</li>
<li>
<span class="badge-toc">09. Evaluation </span> Second Year Mid-Term</li>
<li>
<span class="badge-toc">12. SCI Paper: </span> TBD</li>
<li>
<span class="badge-toc">12. SCI Paper: </span> TBD</li>
</ul>

<h2 id="ÎÖºÎ¨∏-Î¶¨Ïä§Ìä∏">ÎÖºÎ¨∏ Î¶¨Ïä§Ìä∏</h2>

<h3 class="demo-title" style="font-size:1.2rem"> Message Passing with Gating Mechanisms in Multi-agent Reinforcement Learning </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://kros.org/" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">ICROS 2023</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1icI0qQpRqa1pQPypUuVgmG7xhvlXmlQv/view?usp=sharing" target="_blank" rel="noopener noreferrer">Korean Paper</a> | 
  <div class="authors">Bumjin Park, Cheongwoong Kang, and Jaesik Choi, 2023  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
It is important to consider the subjectivity of messages in multi-agent reinforcement learning (MARL). Based
on the assumption that the encoded information is a rather subjective information of the agent encode it, we tackle the problem of
handling objective and subjective information in MARL.
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://drive.google.com/uc?export=view&amp;id=1RHDg7DxJ0ZwQfUUTfXeF4WSYkWntxtl3" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Sample Filtering for Efficient Distillation in Reinforcement Learning </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://kros.org/" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">KRoC 2022</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1lcyaiEu6odTJRO2aAi8B7JyXl0nImtUm/view?usp=sharing" target="_blank" rel="noopener noreferrer">Korean Paper</a> | 
  <div class="authors">Bumjin Park, Cheongwoong Kang, and Jaesik Choi, 2022  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
In this paper, we propose an on-line distillation framework with sample filtering
based on teacher Q-error quantiles. We evaluate the framework in control tasks and show that selecting
proper samples not only increases performance but also reduces the training time.
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://drive.google.com/uc?export=view&amp;id=1WLIFKnE6nH8W8F72NfdGfMCib80aD-NV" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Automatic Analysis of Mobile Robot Decision Process with Layer-wise Relevance Propagation in Reinforcement Learning </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://www.kimst.or.kr/" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">KIMST 2022</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1p4lMXmgvg0XUn1_HuA8rutTfzjASh3XR/view?usp=share_link" target="_blank" rel="noopener noreferrer">Korean Paper</a> | 
  <div class="authors">Cheongwoong Kang, Bumjin Park, and Jaesik Choi, 2022  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
It is challenging to explain the internal mechanisms of reinforcement learning due to the `black
box' nature of deep neural networks. Therefore, we propose an automated analysis method to understand
decision-making processes of reinforcement learning models. Specifically, we identify important input features
for a decision through layer-wise relevance propagation.
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://drive.google.com/uc?export=view&amp;id=1lvHF9k4bKGLmptf2hURyzJq9sSFVQRsc" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Analyzing Conflicting Objectives in Deep Reinforcement Learning-based Target Tracking System </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://www.kimst.or.kr/" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">KIMST 2021</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1rthnTaDxhoHYM1JTmU_JDb-a43wWwrhx/view?usp=sharing" target="_blank" rel="noopener noreferrer">Korean Paper</a> | 
  <div class="authors">Cheongwoong Kang, Bumjin Park, and Jaesik Choi, 2021  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
In this paper, we build a target tracking system based on deep reinforcement learning. Then, we analyze the trade-offs between target following and obstacle avoidance by training the model with varying weights of two objectives. We perform experiments in a virtual simulation environment. The experimental results show that the model exhibits different behaviors depending on the weights of the objectives. 
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://drive.google.com/uc?export=view&amp;id=1rr2OzSgbfIDFSIotOVhTBFXBGuUxFHYD" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Generating Multi-agent Patrol Areas by Reinforcement Learning </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://ieeexplore.ieee.org/abstract/document/9650047" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">ICCAS</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1p_K0mY6WLPOWmI0pJan31tN_m8RvS6a0/view?usp=share_link" target="_blank" rel="noopener noreferrer">Video</a> | 
    <a class="box-demo-link" href="https://drive.google.com/file/d/1Td24gm-56VTeKIZ64_wCYJPm67R8o3ch/view?usp=share_link" target="_blank" rel="noopener noreferrer">Poster</a> | 
  <div class="authors">Bumjin Park, Cheongwoong Kang, and Jaesik Choi, 2021  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">

We designed reinforcement learning environment for distributed patrolling agents. In the partially observable environment, the agents take actions for each one's interest and the non-stationary problem in multi-agent setting encourages the agents not to invade other agent's region. In our environment, the patrolling routes for the agents are generated implicitly.
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://drive.google.com/uc?export=view&amp;id=1MEWgyM_-jzjs9pBCz42i8JEuEst7djg4" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Scheduling PID attitude and position control frequencies for time-optimal quadrotor waypoint tracking under unknown external disturbances </h3>
<div class="demolink">
  | <a class="box-demo-link" href="https://www.mdpi.com/1424-8220/22/1/150" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">Sensors</a> |
  <div class="authors">Cheongwoong Kang, Bumjin Park, and Jaesik Choi, 2021  </div>

</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
We suggest a method to schedule the PID position and attitude control frequencies for time-optimal quadrotor waypoint tracking. The method includes (1) a Control Frequency Agent (CFA) that finds the best control frequencies in various environments, (2) a Quadrotor Future Predictor (QFP) that predicts the next state of a quadrotor, and (3) combining the CFA and QFP for time-optimal quadrotor waypoint tracking under unknown external disturbances.
  </div>
  <div class="column-second" style="width:34%;margin-left:15px;">
  <img src="https://www.mdpi.com/sensors/sensors-22-00150/article_deploy/html/images/sensors-22-00150-g004-550.jpg" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>

<h3 class="demo-title" style="font-size:1.2rem"> Cooperative Multi-Robot Task Allocation with Reinforcement Learning </h3>
<div class="demolink">
  |<a class="box-demo-link" href="https://www.mdpi.com/2076-3417/12/1/272" style="background:#B77EFA" target="_blank" rel="noopener noreferrer">Applied Sciences</a> | 
  <a class="box-demo-link" href="https://github.com/fxnnxc/Cooperative-Multi-Robot-Task-Allocation-with-Reinforcement-Learning" target="_blank" rel="noopener noreferrer">Code</a> | 
  <a class="box-demo-link" href="/side_papers/multirobot_allocation/" style="background:#00B51E;">Project</a> |
  <div class="authors">Bumjin Park, Cheongwoong Kang, and Jaesik Choi, 2021  </div>
</div>
<div class="row">
  <div class="column-first" style="width:60%; font-family:Times New Roman;margin-left:3%;">
This paper deals with the concept of multi-robot task allocation, referring to the assignment of multiple robots to tasks such that an objective function is maximized. The performance of existing meta-heuristic methods worsens as the number of robots or tasks increases. To tackle this problem, a novel Markov decision process formulation for multi-robot task allocation is presented for reinforcement learning. 
  </div>
  <div class="column-second" style="width:34%;margin-left:15px">
  <img src="/assets/side_papers/multirobot-allocation/img5.png" height="80%" width="100%" style="border:1px solid #DDDDDD;border-radius:10px;">
  </div>
</div>
<hr>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>


      <hr>
<!---->
</div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2024 Bumjini  . Powered by Jekyll with al-folio theme. Hosted by GitHub Pages.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>

  <d-bibliography src="/assets/bibliography/">
  </d-bibliography>

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>

    <center>
        <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;">
    </center>
    <hr> 

</html>
